<HTML>
<HEAD>
<TITLE>CTable</TITLE>
<LINK REL="stylesheet" HREF="/stylesheet/" TYPE="text/css">
<LINK REV="made" HREF="mailto:root@what.if.net">
</HEAD>

<BODY>


<!-- INDEX BEGIN -->
<!--

<UL>

	<LI>NAME</LI>
	<LI>SYNOPSIS</LI>
	<LI>OVERVIEW</LI>
	<UL>

		<LI>Similar / related modules on CPAN</LI>
		<LI>Prerequisites</LI>
		<LI>How to learn more</LI>
	</UL>

	<LI>INSTALLATION</LI>
	<LI>INCLUDED SUBCLASSES AND UTILITIES</LI>
	<UL>

		<LI>Subclases</LI>
		<LI>Utilities</LI>
	</UL>

	<LI>CREATING TABLE OBJECTS</LI>
	<UL>

		<LI>Advanced: Using a template object</LI>
	</UL>

	<LI>PARAMETER REFERENCE</LI>
	<UL>

		<LI>Custom field list and custom selection (record list)</LI>
		<LI>Cache behavior controls</LI>
		<LI>Progress routine / setting</LI>
		<LI>File format settings</LI>
		<LI>Encoding of return characters within fields</LI>
		<LI>Sorting-related parameters</LI>
		<LI>Sorting defaults</LI>
		<LI>Miscellaneous parameters</LI>
	</UL>

	<LI>SUBCLASSING</LI>
	<LI>FIELD LIST</LI>
	<LI>DATA COLUMNS (FIELD DATA)</LI>
	<LI>CLEANUP AND VALIDATION</LI>
	<UL>

		<LI>Hints for writing cleanup routines</LI>
		<LI>Roman character set mapping</LI>
		<LI>Utility routines for character mapping</LI>
		<LI>More advanced cleaning and validation</LI>
	</UL>

	<LI>CALCULATIONS USING <CODE>calc()</CODE></LI>
	<LI>&#147;MANUAL&#148; CALCULATIONS</LI>
	<LI>INDEXES</LI>
	<UL>

		<LI>Reverse indexes</LI>
	</UL>

	<LI>DATA ROWS (RECORDS)</LI>
	<LI>ROW / RECORD COUNT (TABLE LENGTH)</LI>
	<LI>SELECTIONS</LI>
	<LI>SEARCHING / SELECTING RECORDS</LI>
	<UL>

		<LI>The effects of modifying a sorted selection</LI>
		<LI>Hints about Boolean logic</LI>
	</UL>

	<LI>SORTING</LI>
	<UL>

		<LI>Using the Named-parameter calling convention with <CODE>sort()</CODE></LI>
	</UL>

	<LI>SORT ORDER</LI>
	<LI>SORT SPECIFICATIONS</LI>
	<LI>DEFAULT SORT DIRECTION</LI>
	<LI>DEFAULT SORT TYPE</LI>
	<LI>SORT ROUTINES: BUILTIN AND CUSTOM</LI>
	<LI>CUSTOM SORT ROUTINE INTERFACE</LI>
	<LI>FREEZING SELECTION &amp; FIELD LIST</LI>
	<LI>LINE ENDINGS</LI>
	<LI>AUTOMATIC CACHEING</LI>
	<UL>

		<LI>Cacheing on <CODE>write()</CODE></LI>
	</UL>

	<LI>AUTOMATIC DIRECTORY CREATION</LI>
	<LI>READING DATA FILES</LI>
	<LI>FILE FORMAT NOTES</LI>
	<LI>WRITING DATA FILES</LI>
	<UL>

		<LI>How <CODE>write()</CODE> calculates the Path</LI>
		<LI>Cacheing with <CODE>write()</CODE></LI>
	</UL>

	<LI>FORMATTED TABLES (Using Data::ShowTable)</LI>
	<LI>APPENDING / MERGING / JOINING TABLES</LI>
	<UL>

		<LI>Combining tables</LI>
		<LI>Joining tables (Looking up data from another table)</LI>
	</UL>

	<LI>INVERTING A TABLE'S ROWS/COLUMNS</LI>
	<LI>PROGRESS MESSAGES</LI>
	<UL>

		<LI>Timed progress</LI>
	</UL>

	<LI>Rejecting or reporting on groups of records and continuing</LI>
	<LI>DEBUGGING / DUMPING</LI>
	<UL>

		<LI>Optional module dependencies</LI>
	</UL>

	<LI>MISCELLANEOUS UTILITY METHODS</LI>
	<LI>GENERAL-PURPOSE UTILITY FUNCTIONS</LI>
	<LI>IMPLEMENTATION LIMITATIONS</LI>
	<LI>CONTRIBUTIONS</LI>
	<LI>SEE ALSO</LI>
	<LI>AUTHOR</LI>
</UL>
-->
<!-- INDEX END -->

<P>
<HR>
<H1>NAME</H1>
<P>Data::CTable - Read, write, manipulate tabular data</P>
<P>
<HR>
<H1>SYNOPSIS</H1>
<PRE>
        ## Read some data files in various tabular formats
        use          Data::CTable;
        my $People = Data::CTable-&gt;new(&quot;people.merge.mac.txt&quot;);
        my $Stats  = Data::CTable-&gt;new(&quot;stats.tabs.unix.txt&quot;);</PRE>
<PRE>
        ## Clean stray whitespace in fields
        $People-&gt;clean_ws();
        $Stats -&gt;clean_ws();</PRE>
<PRE>
        ## Retrieve columns
        my $First = $People-&gt;col('FirstName');  
        my $Last  = $People-&gt;col('LastName' );</PRE>
<PRE>
        ## Calculate a new column based on two others
        my $Full  = [map {&quot;$First-&gt;[$_] $Last-&gt;[$_]&quot;} @{$People-&gt;all()}];</PRE>
<PRE>
        ## Add new column to the table
        $People-&gt;col(FullName =&gt; $Full);</PRE>
<PRE>
        ## Another way to calculate a new column
        $People-&gt;col('Key');
        $People-&gt;calc(sub {no strict 'vars'; $Key = &quot;$Last,$First&quot;;});</PRE>
<PRE>
        ## &quot;Left join&quot; records matching Stats:PersonID to People:Key
        $Stats-&gt;join($People, PersonID =&gt; 'Key');</PRE>
<PRE>
        ## Find certain records
        $Stats-&gt;select_all();
        $Stats-&gt;select(Department =&gt; sub {/Sale/i  });  ## Sales depts
        $Stats-&gt;omit  (Department =&gt; sub {/Resale/i});  ## not Resales
        $Stats-&gt;select(UsageIndex =&gt; sub {$_ &gt; 20.0});  ## high usage</PRE>
<PRE>
        ## Sort the found records
        $Stats-&gt;sortspec('DeptNum'   , {SortType =&gt; 'Integer'});
        $Stats-&gt;sortspec('UsageIndex', {SortType =&gt; 'Number' });
        $Stats-&gt;sort([qw(DeptNum UsageIndex Last First)]);</PRE>
<PRE>
        ## Make copy of table with only found/sorted data, in order
        my $Report = $Stats-&gt;snapshot();</PRE>
<PRE>
        ## Write an output file
        $Report-&gt;write(_FileName =&gt; &quot;Rept.txt&quot;, _LineEnding =&gt; &quot;mac&quot;);</PRE>
<PRE>
        ## Print a final progress message.
        $Stats-&gt;progress(&quot;Done!&quot;);</PRE>
<PRE>
        ## Dozens more methods and parameters available...</PRE>
<P>
<HR>
<H1>OVERVIEW</H1>
<P>Data::CTable is a comprehensive utility for reading, writing,
manipulating, cleaning and otherwise transforming tabular data. The
distribution includes several illustrative subclasses and utility
scripts.</P>
<P>A Columnar Table represents a table as a hash of data columns, making
it easy to do data cleanup, formatting, searching, calculations,
joins, or other complex operations.</P>
<P>The object's hash keys are the field names and the hash values hold
the data columns (as array references).</P>
<P>Tables also store a &#147;selection&#148; -- a list of selected / sorted record
numbers, and a &#147;field list&#148; -- an ordered list of all or some fields
to be operated on.  <CODE>Select()</CODE> and <CODE>sort()</CODE> methods manipulate the
selection list.  Later, you can optionally rewrite the table in memory
or on disk to reflect changes in the selection list or field list.</P>
<P>Data::CTable reads and writes any tabular text file format including
Merge, CSV, Tab-delimited, and variants.  It transparently detects,
reads, and preserves Unix, Mac, and/or DOS line endings and tab or
comma field delimiters -- regardless of the runtime platform.</P>
<P>In addition to reading data files, CTable is a good way to gather,
store, and operate on tabular data in memory, and to export data to
delimited text files to be read by other programs or interactive
productivity applications.</P>
<P>To achieve extremely fast data loading, CTable caches data file
contents using the Storable module.  This can be helpful in CGI
environments or when operating on very large data files.  CTable can
read an entire cached table of about 120 megabytes into memory in
about 10 seconds on an average mid-range computer.</P>
<P>For simple data-driven applications needing to store and quickly
retrieve simple tabular data sets, CTable provides a credible
alternative to DBM files or SQL.</P>
<P>For data hygiene applications, CTable forms the foundation for writing
utility scripts or compilers to transfer data from external sources,
such as FileMaker, Excel, Access, personal organizers, etc. into
compiled or validated formats -- or even as a gateway to loading data
into SQL databases or other destinations.  You can easily write short,
repeatable scripts in Perl to do reporting, error checking, analysis,
or validation that would be hard to duplicate in less-flexible
application environments.</P>
<P>The data representation is simple and open so you can directly access
the data in the object if you feel like it -- or you can use accessors
to request &#147;clean&#148; structures containing only the data or copies of
it.  Or you can build your own columns in memory and then when you're
ready, turn them into a table object using the very flexible <CODE>new()</CODE>
method.</P>
<P>The highly factored interface and implementation allow fine-grained
subclassing so you can easily create useful lightweight subclasses.
Several subclasses are included with the distribution.</P>
<P>Most defaults and parameters can be customized by subclassing,
overridden at the instance level (avoiding the need to subclass too
often), and further overridden via optional named-parameter arguments
to most major method calls.</P>
<P>
<H2>Similar / related modules on CPAN</H2>
<P>The Data::Table module by Yingyao Zhou &amp; Guangzhou Zou offers similar
functionality, but uses a different underlying data representation
(2-dimensional array), and has a somewhat different feature set.
Check it out.  Maybe you will prefer it for your application.</P>
<PRE>
        <A HREF="http://search.cpan.org/search?mode=module&query=Data::Table">http://search.cpan.org/search?mode=module&amp;query=Data::Table</A></PRE>
<P>The Data::ShowTable module renders tables in various viewable formats.
CTable relies on ShowTable's ShowBoxTable method to implement its own
<CODE>format()</CODE> and <CODE>out()</CODE> methods.</P>
<PRE>
        <A HREF="http://search.cpan.org/search?mode=module&query=Data::ShowTable">http://search.cpan.org/search?mode=module&amp;query=Data::ShowTable</A></PRE>
<P>
<H2>Prerequisites</H2>
<P>The CTable documentation, source code, and examples assume familiarity
with large nested data structures, object-oriented syntax and
terminology, and comfort working with array and hash references and
array and hash slice syntax.</P>
<P>See the perlref man page for more on these topics.</P>
<P>
<H2>How to learn more</H2>
<P>Dozens more methods, parameters, and examples are described below.</P>
<P>See the full source code in CTable.pm.</P>
<P>Or, after installing, read the man page using:</P>
<PRE>
        man     Data::CTable
        perldoc Data::CTable</PRE>
<P>See the eg/ (examples) folder in the Data::CTable distribution and the
test.pl script for scripts demonstrating every CTable method.</P>
<P>For latest version and other news, check the Data::CTable home page:</P>
<PRE>
        <A HREF="http://christhorman.com/projects/perl/Data-CTable/">http://christhorman.com/projects/perl/Data-CTable/</A></PRE>
<P>Or search CPAN:</P>
<PRE>
        <A HREF="http://search.cpan.org/search?mode=module&query=Data::CTable">http://search.cpan.org/search?mode=module&amp;query=Data::CTable</A></PRE>
<P>
<HR>
<H1>INSTALLATION</H1>
<P>Using CPAN module:</P>
<PRE>
        perl -MCPAN -e 'install Data::CTable'</PRE>
<P>Or manually:</P>
<PRE>
        tar xzvf Data-CTable*gz
        cd Data-CTable-?.??
        perl Makefile.PL
        make
        make test
        make install</PRE>
<P>
<HR>
<H1>INCLUDED SUBCLASSES AND UTILITIES</H1>
<P>In addition to the module itself, there are a number of subclasses and
simple utilities included with the Data::CTable distribution.</P>
<P>
<H2>Subclases</H2>
<P>The Data::CTable distribution includes these example subclasses.  Each
is installed in your Perl environment along with the main module, and
so may be used by your scripts.  Each has its own man/perldoc page
containing more detail.</P>
<P><STRONG>Data::CTable::ProgressLogger</STRONG> is a subclass that logs all progress
messages to a list within the object itself rather than (merely)
echoing them to STDERR.  Later, you may retrieve and examine the list.</P>
<P><STRONG>Data::CTable::Script</STRONG> is a virtual subclass that includes class and
object methods that make it easy to write a simple interactive
command-line program that parses options and outputs a table.</P>
<P><STRONG>Data::CTable::Listing</STRONG> is a very useful subclass of
Data::CTable::Script that implements a souped-up Unix-like &#147;ls&#148; (file
listing) command -- it first gets an optionally-recursive listing of
any number of files and/or directories, builds a list of their full
absolute or relative paths, then build a Data::CTable::Listing object
that contains all the paths, plus about 25+ other pieces of useful
information about each file or directory.</P>
<P>The &#147;tls&#148; utility, below, is simply a command-line cover for this
class, but you could use this class in your own scripts in order to
get detailed file listings.</P>
<P>
<H2>Utilities</H2>
<P>Each of these utilities is provided mainly so you can see mature
examples of how to use Data::CTable in real-world scripts.</P>
<P>But each is also genuinely useful, too, and you may enjoy adding them
to your regular bag of tricks or using them as an easily-modifiable
basis for scripts of your own.</P>
<P>On most systems, these will be installed in an appropriate directory
in your path when you install CTable, and hence will be executable
just by typing their file name.  (On Windows, they'll be wrapped by a
.bat file and installed in C:\Perl\bin or equivalent.  On *nix,
they'll be in /usr/bin/ or equivalent.)</P>
<P><STRONG>tls</STRONG> is a command-line utility that wraps Data::CTable::Listing to
implement a variant on the classic Unix &#147;ls&#148; command in which an
internal CTable object is used to hold and calculate a very large
amount of meta-data about each file and directory and then output that
data in formatted tables, or as any kind of delimited text file, and
with much more flexibility and control over included data, and sort
and sub-sort order than with ls.</P>
<P><STRONG>tshow</STRONG> is a command-line utility that reads each of its arguments as
a Data::CTable file and then calls the <CODE>out()</CODE> method to display its
entire contents.  (Warning: <CODE>out()</CODE> is slow with very large data sets.)</P>
<P><STRONG>getweather</STRONG> is a command-line utility that takes a US zip code,
grabs the local weather report from a popular weather web site and
uses a CTable object to store, process, and clean, and present the
table of weather data that results in a simple text format.</P>
<P>
<HR>
<H1>CREATING TABLE OBJECTS</H1>
<PRE>
        ## Create an object / read file(s) / override params</PRE>
<PRE>
        use  Data::CTable;</PRE>
<PRE>
        $t = Data::CTable-&gt;new()
        $t = Data::CTable-&gt;new($File)
        $t = Data::CTable-&gt;new($File1, $File2....)
        $t = Data::CTable-&gt;new($Params)
        $t = Data::CTable-&gt;new($Params, $File1)
        $t = Data::CTable-&gt;new($Params, $File1, $File2....)</PRE>
<PRE>
        ## Internal initializer (subclassable): called for you by new()</PRE>
<PRE>
        $t-&gt;initialize()</PRE>
<P>If the first argument to <CODE>new()</CODE> is a hash ref, it is the $Params hash
of initial parameters and/or data columns which, if supplied will form
the starting point for the object being created.  Any non-hash and/or
further arguments to <CODE>new()</CODE> are treated as file names to be opened.</P>
<P>If supplied, data in the $Params hash will be shallowly copied -- the
original hash object passed will not be used, but any sub-structures
within it will now &#147;belong&#148; to the resulting new object which will
feel free to manipulate them or discard them.</P>
<P>Then, any parameters not supplied (usually most of them) will be
defaulted for you because <CODE>new()</CODE> will call the internal method
<CODE>initialize()</CODE> before the object is finished and returned.</P>
<P>See the PARAMETER REFERENCE section below for the parameters you can
choose to supply or have defaulted for you.</P>
<P>Any file name arguments will be read and appended into a single
object.  If any of the files fails to be read, then <CODE>new()</CODE> will fail
(return a false value) and no object will be created.</P>
<P><CODE>initialize()</CODE> makes sure there is a legal and consistent value for
every internal parameter in the object.  Generally, <CODE>initialize()</CODE>
leaves alone any parameters you supplied to new(), and simply sets
default values for any that were not yet supplied.</P>
<P>You should never need to call <CODE>initialize()</CODE> directly.</P>
<P>After calling initialize(), <CODE>new()</CODE> then calls the <CODE>append_files_new()</CODE>
method to process the filename arguments.  This method then calls
<CODE>read()</CODE> on the first filename, and then append_file on all subsequent
file names, appending them to the first, in sequence.</P>
<P>See <CODE>append()</CODE> for an explanation of how the data from multiple files is
combined into a single table.</P>
<P>
<H2>Advanced: Using a template object</H2>
<PRE>
        ## Calling new() with a template object</PRE>
<PRE>
        $v =           $t-&gt;new()                           
        $v =           $t-&gt;new($File)                      
        $v =           $t-&gt;new($File1, $File2....)         
        $v =           $t-&gt;new($Params)                    
        $v =           $t-&gt;new($Params, $File1)                    
        $v =           $t-&gt;new($Params, $File1, $File2....)</PRE>
<P>You can also call $t-&gt;<CODE>new()</CODE> to use an existing object, $t, as a
template for the new object.  $t-&gt;<CODE>new()</CODE> will create a new object of
the same class or subclass as the template object.  Furthermore, the
template object, if provided, will be used as a starting point for the
resulting object -- in fact, it will initially share shallow copies of
all data columns, if any, and all internal parameters and data
structures, if any.</P>
<P>This advanced shared-data technique could be used to create two
separate table objects that share and operate on the same underlying
data columns in memory but have different custom field lists, custom
selections, sort behavior, etc.  But don't do this unless you're sure
you understand what you're doing, because changing data in one table
would change it in the other.</P>
<P>
<HR>
<H1>PARAMETER REFERENCE</H1>
<P>The parameters listed here are recognized by new(), initialize(), and
by many functions that use the named-parameter calling convention,
such as read(), write(), sort(), and others.</P>
<P>Any parameter listed may be specified when using new().</P>
<P>Most parameters should not be directly accessed or manipulated once
the object has been created, except those that have appropriate
accessor methods described throughout in this documentation.</P>
<P>Each parameter in the lists below is listed along with its defaulting
logic as performed by <CODE>new()</CODE> via initialize().</P>
<P>
<H2>Custom field list and custom selection (record list)</H2>
<DL>
<DT><STRONG>_FieldList ||= undef;</STRONG><BR>
<DD>
This is the ordered list (array reference) of columns / fields present
in the object.  It is set by <CODE>read()</CODE> to reflect the names and order of
the fields encountered or actually read from in the incoming data
file, if any.  Initially this list is undefined, and if removed or
left undefined, then the de-facto field list will be a list of all
columns present in the table object, in alphabetical order (see
<CODE>fieldlist()</CODE> and fieldlist_all()).
<P>Normally, all fields present in the table object would be listed in
the field list.</P>
<P>However, this parameter may be set in the object (or overridden in
named-parameter function calls like read(), write(), etc.) to cause a
subset of fields to be read, written or otherwise used.  If a subset
field list is specified before reading a data file, then ONLY fields
listed will be read -- this is a way to read just certain fields from
a very large file, but may not always be what you want.</P>
<P>Specifying the field list before calling <CODE>read()</CODE> is required if the
data file has no header row giving names to its fields -- the names
you specify in the field list, in order, will be applied to the data
file being read.  See the _HeaderRow parameter, below.</P>
<P>If a subset field list is used after columns are already loaded in
memory, the columns not listed in the field list will still be present
in the object (and can be listed by calling fieldlist_all()), but they
will be omitted from most operations that iterate over fields.</P>
<P></P>
<DT><STRONG>_Selection ||= undef;</STRONG><BR>
<DD>
This is a list of the record numbers of &#147;selected&#148; records in the
table, possibly indicating sorted order.
<P>If absent, then all records are considered to be selected, in
&#147;natural&#148; order -- i.e. the order they occur in the file.</P>
<P>You can create and set your own selection list or get and modify an
existing one.  Deleting it resets the selection (for example, by
calling select_all()).</P>
<P>Calling <CODE>sort()</CODE> will create a _Selection if none existed.  Otherwise it
operates by modifying the existing _Selection, which may be a subset
of all record numbers.</P>
<P></P></DL>
<P>
<H2>Cache behavior controls</H2>
<P>See sections related to Cacheing, below.</P>
<DL>
<DT><STRONG>_CacheOnRead   = 1 unless exists</STRONG><BR>
<DD>
Boolean: whether data files read by the <CODE>read()</CODE> method should be cached
after reading.  Once cached, the data will be read from the cache
instead of the original file the NEXT TIME <CODE>READ()</CODE> IS CALLED, but only
if: 1) the cache file is found, and 2) its date is later than the
original.  Otherwise, the cache file is ignored or re-written.
Cacheing can be up to 10x faster than parsing the file, so it's almost
always worth doing in any situation where you'll be reading a data
file more often than writing it.
<P>This parameter defaults to true.</P>
<P></P>
<DT><STRONG>_CacheOnWrite  = 0 unless exists</STRONG><BR>
<DD>
Boolean: whether tables written by the <CODE>write()</CODE> method should be cached
after writing.  This defaults to false on the assumption that the
program won't need to re-read a file it just wrote.  However, this
behavior would be useful if a later step in your program or another
program will be reading the file that was written and would benefit
from having the cacheing already done.  Cacheing a file after writing
is quite fast since the data is already in memory and of course it
speeds up subsequent <CODE>read()</CODE> operations by up to 10x.
<P></P>
<DT><STRONG>_CacheExtension = &#147;.cache&#148; unless exists</STRONG><BR>
<DD>
This is the file name extension that is added to a file's name to
determine the name of its corresponding cache file.  (First, any
existing extension, if any, is removed.)  If this extension is empty,
then the cache file will be named the same as the original assuming
the cache file is being stored in a different directory.  (See next
setting.)
<P></P>
<DT><STRONG>_CacheSubDir    =  &#147;cache&#148; unless exists</STRONG><BR>
<DD>
This is the absolute or relative path to the subdirectory that should
be used to store the cache files.  The default value is the relative
path to a directory called &#147;cache&#148;.  Relative paths will be appended
to the directory path containing the original file being read.
<P>Absolute cache paths (such as /tmp or c:\temp\) can also be used.</P>
<P>Override _CacheExtension and _CacheSubdir in a subclass, in each
object, or in each call to <CODE>read()</CODE> or <CODE>write()</CODE> in order to have the
cache files stored elsewhere.  But remember: unless you use the same
cache settings next time you read the same file, the cache files will
be orphaned.</P>
<P></P></DL>
<P>
<H2>Progress routine / setting</H2>
<DL>
<DT><STRONG>_Progress       = undef unless exists</STRONG><BR>
<DD>
The _Progress setting controls the routing of diagnostic messages.
Four possible settings are recognized:
<PRE>
        undef (default)        The class's progress settings are used.
        subroutine reference   Your own custom progress routine.
        true                   Built-in progress_default() method used.
        0/false                No progress messages for this object.</PRE>
<P>See the PROGRESS section for a description of the interface of custom
progress routines and for details on how the builtin one works.</P>
<P></P></DL>
<P>
<H2>File format settings</H2>
<DL>
<DT><STRONG>_LineEnding    ||= undef;</STRONG><BR>
<DD>
_LineEnding indicates the line ending string or setting to be used to
read a file, the setting that actually <EM>was</EM> used to read a file,
and/or the line ending that will be used to write a file.
<P>Set this parameter to force a particular encoding to be used.</P>
<P>Otherwise, leave it undef.  The program will Do What You Mean.</P>
<P>If _LineEnding is undef when <CODE>read()</CODE> is called, <CODE>read()</CODE> will try to
guess the line ending type by inspecting the first file it reads.
Then it will set this setting for you.  It can detect DOS, Unix, and
Mac line endings.</P>
<P>If _LineEnding is undef when <CODE>write()</CODE> is called, <CODE>write()</CODE> will use
<CODE>&quot;\n&quot;</CODE>, which yields different strings depending on the current
runtime platform: \x0A on Unix; \x0D in MacPerl, \x0D\x0A on DOS.</P>
<P>Otherwise, <CODE>write()</CODE> uses the value defined in _LineEnding, which would
match the value filled in by <CODE>read()</CODE> if this object's data originally
had been read from a file.  So if you read a file and then later write
it out, the line endings in the written file will match the format of
original unless you override _LineEnding specifically.</P>
<P>Since Data::CTable supports reading and writing all common endings,
base your decision on line ending format during <CODE>write()</CODE> on the needs
of other programs you might be using.</P>
<P>For example: FileMaker Pro and Excel crash / hang if Unix line endings
are used, so be sure to use the ending format that matches the needs
of the other programs you plan to use.</P>
<P>As a convenience, you may specify and retrieve the _LineEnding setting
using the mnemonic symbols &#147;mac&#148;, &#147;dos&#148; and &#147;unix.&#148;  These special
values are converted to the string values shown in this chart:</P>
<PRE>
         symbol   string value  chars  decimal     octal     control
        -------------------------------------------------------------
          dos     &quot;\x0D\x0A&quot;    CR/LF   13,10    &quot;\015\012&quot;   ^M^J
          mac     &quot;\x0D&quot;        CR      13       &quot;\015&quot;       ^M
          unix    &quot;\x0A&quot;        LF      10       &quot;\012&quot;       ^J</PRE>
<P>See the section LINE ENDINGS, below, for accessor methods and
conversion utilities that help you get/set this parameter in either
symbolic format or string format as you prefer.</P>
<P></P>
<DT><STRONG>_FDelimiter    ||= undef;</STRONG><BR>
<DD>
_FDelimiter is the field delimiter between field names in the header
row (if any) and also between fields in the body of the file.  If
undef, <CODE>read()</CODE> will try to guess whether it is tab <CODE>&quot;\t&quot;</CODE> or comma
&lt;&#147;,&#148;&gt;, and set this parameter accordingly.  If there is only one field
in the file, then comma is assumed by <CODE>read()</CODE> and will be used by
write().
<P>To guess the delimiter, the program looks for the first comma or tab
character in the header row (if present) or in the first record.
Whichever character is found first is assumed to be the delimiter.</P>
<P>If you don't want the program to guess, or you have a data file format
that uses a custom delimiter, specify the delimiter explicitly in the
object or when calling <CODE>read()</CODE> or make a subclass that initializes this
value differently.  On write(), this will default to comma if it is
empty or undef.</P>
<P></P>
<DT><STRONG>_QuoteFields    = undef unless exists</STRONG><BR>
<DD>
_QuoteFields controls how field values are quoted by <CODE>write()</CODE> when
writing the table to a delimited text file.
<P>An undef value (the default) means &#147;auto&#148; -- each field is checked
individually and if it contains either the _FDelimiter character or a
double-quote character, the field value will be surrounded by
double-quotes as it is written to the file.  This method is slower to
write but faster to read, and may make the output easier for humans to
read.</P>
<P>A true value means always put double-quotes around every field value.
This mode is faster to write but slower to read.</P>
<P>A zero value means never to use double-quotes around field values and
not to check for the need to use them.  This method is the fastest to
read and write.  You may use it when you are certain that your data
can't contain any special characters.  However, if you're wrong, this
mode will produce a corrupted file in the event that one of the fields
does contain the active delimiter (such as comma or tab) or a quote.</P>
<P></P>
<DT><STRONG>_HeaderRow      = 1 unless exists</STRONG><BR>
<DD>
_HeaderRow is a boolean that says whether to expect a header row in
data files.  The default is true: a header row is required.  If false,
_FieldList MUST be present before calling <CODE>read()</CODE> or an error will be
generated.  In this latter case, _FieldList will be assumed to give
the correct names of the fields in the file, in order, before the file
is read.  In other words, the object expects that either a) it can get
the field names from the file's header row or b) you will supply them
before <CODE>read()</CODE> opens the file.
<P></P></DL>
<P>
<H2>Encoding of return characters within fields</H2>
<DL>
<DT><STRONG>_ReturnMap       = 1 unless exists</STRONG><BR>
<DD>
_ReturnMap says that returns embedded in fields should be decoded on
<CODE>read()</CODE> and encoded again on write().  The industry-standard encoding
for embedded returns is ^K (ascii 11 -- but see next setting to change
it).  This defaults to true but can be turned off if you want data
untouched by read().  This setting has no effect on data files where
no fields contain embedded returns.  However, it is vital to leave
this option ON when writing any data file whose fields could contain
embedded returns -- if you have such data and call <CODE>write()</CODE> with
_ReturnMap turned off, the resulting file will be an invalid Merge/CSV
file and might not be re-readable.
<P>When these fields are decoded on read(), encoded returns are converted
to <CODE>&quot;\n&quot;</CODE> in memory, whatever its interpretation may be on the current
platform (\x0A on Unix or DOS; \x0D on MacPerl).</P>
<P>IMPORTANT NOTE: When these fields are encoded by write(), any
occurrence of the current _LineEnding being used to write the file is
searched and encoded FIRST, and THEN, any occurrence of &#147;\n&#148; is also
searched and encoded.  For example, if using mac line endings (^M) to
write a file on a Unix machine, any ^M characters in fields will be
encoded, and then any &#147;\n&#148; (^J) characters will ALSO be encoded.  This
may not be what you want, so be sure you know how your data is encoded
in cases where your field values might contain any ^J and/or ^M
characters.</P>
<P>IMPORTANT NOTE: If you turn _ReturnMap off, fields with returns in
them will still be double-quoted correctly.  Some parsers of tab- or
comma-delimited files are able to support reading such files.
HOWEVER, the parser in this module's <CODE>read()</CODE> method DOES NOT currently
support reading files in which a single field value appears to span
multiple lines in the file.  If you have a need to read such a file,
you may need to write your own parser as a subclass of this module.</P>
<P></P>
<DT><STRONG>_ReturnEncoding    ||= &#147;\x0B&#148;;</STRONG><BR>
<DD>
This is the default encoding to assume when embedding return
characters within fields.  The industry standard is &#147;\x0B&#148; (ascii 11 /
octal \013 / ^K) so you should probably not ever change this setting.
<P>When fields are encoded on write(), <CODE>&quot;\n&quot;</CODE> is converted to this
value.  Note that different platforms use different ascii values for
<CODE>&quot;\n&quot;</CODE>, which is another good reason to leave the ReturnEncoding
feature enabled when calling write().</P>
<P>To summarize: this module likes to assume, and you should too, that
returns in data files on disk are encoded as &#147;\x0B&#148;, but once loaded
into memory, they are encoded as the current platform's value of
<CODE>&quot;\n&quot;</CODE>.</P>
<P></P>
<DT><STRONG>_MacRomanMap       = undef unless exists</STRONG><BR>
<DD>
Data::CTable assumes by default that you want field data in memory to
be in the ISO 8859-1 character set (the standard for Latin 1 Roman
characters on Unix and Windows in the English and Western European
languages -- and also the default encoding for HTML Web pages).
<P>_MacRomanMap controls the module's optional mapping of Roman
characters from Mac format on disk to ISO format in memory when
reading and writing data files.  These settings are recognized:</P>
<PRE>
        undef   ## Auto: Read/write Mac chars if using Mac line endings  
        1       ## On:   Assume Mac char set in all fields
        0       ## Off:  Don't do any character mapping at all</PRE>
<P>The default setting is undef, which enables &#147;Auto&#148; mode: files found
to contain Mac line endings will be assumed to contain Mac upper-ASCII
characters and will be mapped to ISO on read(); and files to be
written with Mac line endings will mapped back from ISO to Mac format
on write().</P>
<P>If your data uses any non-Latin-1 character sets, or binary data, or
you really want Mac upper-ASCII characters in memory, or you just
don't want this module messing with your encodings, set this option to
0 (Off) or make a subclass that always sets it to 0.</P>
<P>See also the <CODE>clean()</CODE> methods that can help you translate just the
columns you want after reading a file or before writing it, which may
be faster for you if only a few fields might contain high-ASCII
characters.</P>
<P></P>
<DT><STRONG>_FileName          ||= undef;</STRONG><BR>
<DD>
This is the name of the file that should be read from or WAS read
from.  (read() will set _FileName to the value it used to read the
file, even if _FileName was only supplied as a named parameter.)
<P>This name will also be used, unless overridden, to re-write the file
again, but with an optional extension added.  (See next setting.)</P>
<P></P>
<DT><STRONG>_WriteExtension = &#147;.out&#148; unless exists</STRONG><BR>
<DD>
The _WriteExtension is provided so that CTable won't overwrite your
input data file unless you tell it to.
<P>_WriteExtension will be added to the object's _FileName setting to
create a new, related file name, before writing....  UNLESS _FileName
is supplied as an direct or named parameter when calling write().</P>
<P>In the latter case, <CODE>write()</CODE> uses the file name you supply and adds no
extension, even if this would mean overwriting the original data file.</P>
<P>To add _WriteExtension, <CODE>write()</CODE> places it prior to any existing final
extension in the _FileName:</P>
<PRE>
        _FileName             default file name used by write()
        --------------------------------------------------------------
        People.merge.txt      People.merge.out.txt
        People                People.out</PRE>
<P>If you want to always overwrite the original file without having to
supply _FileName each time, simply set _WriteExtension to undef in a
subclass or in each instance.</P>
<P>If _CacheOnWrite is true, then the _WriteExtension logic is applied
first to arrive at the actual name of the file to be written, and then
the _CacheExtension logic is applied to that name to arrive at the
name of the cache file to be written.</P>
<P></P></DL>
<P>
<H2>Sorting-related parameters</H2>
<DL>
<DT><STRONG>_SortOrder ||= undef;</STRONG><BR>
<DD>
_SortOrder is the list of fields which should be used as primary,
secondary, etc. sort keys when <CODE>sort()</CODE> is called.  Like other
parameters, it may be initialized by a subclass, stored in the object,
or provided as a named parameter on each call to sort().
<P>If _SortOrder is empty or undefined, then <CODE>sort()</CODE> sorts the records by
record number (i.e. they are returned to their &#147;natural&#148; order).</P>
<P></P>
<DT><STRONG>_SortSpecs ||= {};</STRONG><BR>
<DD>
_SortSpecs is a hash of specifications for the SortType and
SortDirection of fields on which sorting may be done.  For any field
missing a sort spec or the SortType or SortDirection components of its
sort spec, the _DefaultSortType and _DefaultSortDirection settings
will be used.  So, for example, if all fields are of type String and
you want them to sort Ascending, then you don't need to worry about
_SortSpecs.  You only need to provide specs for fields that don't take
the default settings.
<P>_SortSpecs might look like this:</P>
<PRE>
        {Age      =&gt; {SortType =&gt; 'Integer'}, 
         NameKey  =&gt; {SortType =&gt; 'Text', SortDirection =&gt; -1}}</PRE>
<P></P>
<DT><STRONG>_SRoutines ||= {};</STRONG><BR>
<DD>
_SRoutines is a hash mapping any new SortTypes invented by you to your
custom subroutines for sorting that type of data.  (See the section on
sort routines, below, for a full discussion.)
<P></P></DL>
<P>
<H2>Sorting defaults</H2>
<DL>
<DT><STRONG>_DefaultSortType      ||= 'String';</STRONG><BR>
<DD>
If you sort using a field with no sort spec supplied, or whose sort
spec omits the SortType, it will get its SortType from this parameter.
<P>See the sections below on SORT TYPES and SORT ROUTINES.</P>
<P></P>
<DT><STRONG>_DefaultSortDirection ||= 1;</STRONG><BR>
<DD>
If you sort using a field with no sort spec supplied, or whose sort
spec omits the SortDirection, it will get its SortDirection from this
parameter.
<P>Legal sort directions are: 1 (Ascending) or -1 (Descending).</P>
<P>See the section below on DEFAULT SORT DIRECTION.</P>
<P></P></DL>
<P>
<H2>Miscellaneous parameters</H2>
<DL>
<DT><STRONG>_ErrorMsg  ||= ``'';</STRONG><BR>
<DD>
This parameter is set by <CODE>read()</CODE> or <CODE>write()</CODE> methods that encounter an
error (usually a parameter error or file-system error) that prevents
them from completing.  If those methods or any methods that call them
return a false value indicating failure, then _ErrorMsg will contain a
string explaining the problem.  The message will also have been passed
to the <CODE>progress()</CODE> method for possible console feedback.
<P></P>
<DT><STRONG>_Subset</STRONG><BR>
<DD>
This parameter is set to 1 (true) by <CODE>read()</CODE> if the last call to <CODE>read()</CODE>
brought in a subset of the fields available in the file; 0 otherwise.
<P>The object uses this field internally so it knows to abandon any cache
files that might not contain all requested fields upon read().</P>
<P></P></DL>
<P>
<HR>
<H1>SUBCLASSING</H1>
<P>Most subclasses will override <CODE>initialize()</CODE> to set default values for
the parameters of the parent class and then they may provide default
values for other subclass-specific parameters.  Then, the subclass's
<CODE>initialize()</CODE> should call SUPER::initialize() to let the parent
<CODE>class(es)</CODE> take care of the remaining ones.</P>
<P>Every <CODE>initialize()</CODE> method should always allow for parameters to have
already been provided by the $Params hash or template object.  It
should not overwrite any valid values that already exist.</P>
<P>The following sample subclass changes the default setting of the
_Progress parameter from undef to 1 and then overrides the
<CODE>progress_default()</CODE> method to log all progress messages into a new
&#147;_ProgrLog&#148; (progress log) parameter stored in the object.</P>
<PRE>
        BEGIN
        {   ## Data::CTable::ProgressLogger: store messages in the object</PRE>
<PRE>
            package Data::CTable::ProgressLogger;
            use vars qw(@ISA); @ISA=qw(Data::CTable);</PRE>
<PRE>
            sub initialize       ## Add a new param; change one default
            {
                my $this           = shift;
                $this-&gt;{_Progress} = 1 unless exists($this-&gt;{_Progress});
                $this-&gt;{_ProgrLog} ||= [];
                $this-&gt;SUPER::initialize();
            }</PRE>
<PRE>
            sub progress_default ## Log message to object's ProgMsgs list
            {
                my $this            = shift;
                my ($msg)           = @_;
                chomp                                       $msg;
                push @{$this-&gt;{_ProgrLog}}, localtime() . &quot; $msg&quot;;</PRE>
<PRE>
                return(1);
            }</PRE>
<PRE>
            sub show_log                 ## Use Dumper to spit out the log list
            {
                my $this            = shift;
                $this-&gt;dump($this-&gt;{_ProgrLog});
            }
        }</PRE>
<PRE>
        ## Later...</PRE>
<PRE>
        my $Table = Data::CTable::ProgressLogger-&gt;new(&quot;mydata.txt&quot;);
        # ... do stuff...
        $Table-&gt;write();
        $Table-&gt;show_log();</PRE>
<P>
<HR>
<H1>FIELD LIST</H1>
<PRE>
        ## Getting / setting the object's _FieldList</PRE>
<PRE>
        $t-&gt;fieldlist()             ## Get _FieldList or fieldlist_all()
        $t-&gt;fieldlist_get()         
        $t-&gt;fieldlist_hash()        ## Get fieldlist() as keys in a hash
</PRE>
<PRE>

        $t-&gt;fieldlist_all()         ## Get all fields (ignore _FieldList)</PRE>
<PRE>

        $t-&gt;fieldlist($MyList)      ## Set field list (_FieldList param)
        $t-&gt;fieldlist_set($MyList)</PRE>
<PRE>
        $t-&gt;fieldlist(0)            ## Remove field list (use default)
        $t-&gt;fieldlist_set()</PRE>
<PRE>
        $t-&gt;fieldlist_force($MyList)## Set list; remove non-matching cols</PRE>
<PRE>
        $t-&gt;fieldlist_truncate()    ## Just remove nonmatching cols</PRE>
<PRE>
        $t-&gt;fieldlist_default()     ## Default field list (alpha-sorted)</PRE>
<PRE>
        $t-&gt;fieldlist_add($MyName)    ## Append new name to custom list.
        $t-&gt;fieldlist_delete($MyName) ## Delete name from custom list.</PRE>
<P>A CTable object can optionally have a custom field list.  The custom
field list can store both the ORDER of the fields (which otherwise
would be unordered since they are stored as keys in a hash), and also
can be a subset of the fields actually in the object, allowing you to
temporarily ignore certain effectively-hidden fields for the benefit
of certain operations.  The custom field list can be changed or
removed at any time.</P>
<P>The custom field list is stored in the private _FieldList parameter.</P>
<P><CODE>fieldlist()</CODE> always returns a list (reference).  The list is either the
same list as _FieldList, if present, or it is the result of calling
fieldlist_default().  In CTable, <CODE>fieldlist_default()</CODE> in turn calls
<CODE>fieldlist_all()</CODE> -- hence <CODE>fieldlist()</CODE> would yield an auto-generated
list of all fields in alphabetical order.</P>
<P><CODE>fieldlist_all()</CODE> can be called directly to get a list of all fields
present regardless of the presence of a _FieldList parameter.  The
list is an alphabetical case-insensitively sorted list of all hash
keys whose names do not begin with an underscore.</P>
<P>You could override this method if you want a different behavior. Or,
you could create your own custom field list by calling <CODE>fieldlist_all()</CODE>
and removing fields or ordering them differently.</P>
<P>To set a custom field list (in _FieldList), call <CODE>fieldlist()</CODE> or
<CODE>fieldlist_set()</CODE> with a list (reference).  The list must be a list of
strings (field names) that do not begin with underscore.  The object
owns the list you supply.</P>
<P>To remove a custom field list (and let the default be used), call
<CODE>fieldlist(0)</CODE> or <CODE>fieldlist_set()</CODE> with no arguments (these will return
the fieldlist that was deleted, if any).</P>
<P><CODE>fieldlist_freeze()</CODE> &#147;freezes&#148; the fieldlist in its current state.  This
is equivalent to the following:</P>
<PRE>
        $t-&gt;fieldlist_set($t-&gt;fieldlist());</PRE>
<P>... which would force the fieldlist to $t-&gt;<CODE>fieldlist_all()</CODE> if and only
if there is not already a custom _FieldList present.</P>
<P>IMPORTANT NOTE ABOUT PARTIAL FIELD LISTS: When setting a field list,
the object ensures that all fields (columns) mentioned in the list are
present in the object -- it creates empty columns of the correct
length as necessary.  However, it does NOT delete any fields not
mentioned in the field list.  This allows you to manipulate the field
list in order to have certain fields be temporarily ignored by all
other methods, then alter, restore, or remove it (allow it to revert
to default) and they will be effectively unhidden again.  Some methods
(such as cols(), write(), etc.) also allow you to specify a custom
field list that will override any other list just during the execution
of that method call but will not modify the object itself.</P>
<P>Call <CODE>fieldlist_force()</CODE> to set the list AND have any non-listed fields
also deleted at the same time (by calling <CODE>fieldlist_truncate()</CODE>
internally).  You can also just delete individual columns one-by-one,
of course, using the column-manipulation methods and the custom
fieldlist, if any, will be appropriately updated for you.</P>
<P><CODE>fieldlist_truncate()</CODE> deletes any fields found in the table but not
currently present in _FieldList.  A hash of the deleted columns is
returned to the caller.  If there is no _FieldList, then this method
does nothing.</P>
<P><CODE>fieldlist_default()</CODE> just calls <CODE>fieldlist_all()</CODE> in this implementation,
but could be changed in subclasses.</P>
<P><CODE>fieldlist_add()</CODE> is the internal method that adds a new field name to
the custom field list (if present) and if the field name was not
already on the list.  It is called by other methods any time a new
column is added to the table.  Don't call it directly unless you know
what you're doing because the corresponding column won't be created.
(Instead, use <CODE>col().)</CODE>  The field name is appended to the end of the
existing custom field list.  If there is no custom field list, nothing
is done.</P>
<P><CODE>fieldlist_delete()</CODE> is the internal method that deletes a field name
from the custom field list (if present).  It is called by other
methods when columns are deleted, but it does not actually delete the
columns themselves, so use with caution: deleting a field from the
custom field list effectively hides the field.  This method has no
effect, however, if there is no custom field list present.  So don't
call this method directly unless you know what you're doing.</P>
<P>
<HR>
<H1>DATA COLUMNS (FIELD DATA)</H1>
<PRE>
        ## Getting or setting data in entire columns</PRE>
<PRE>
        $t-&gt;{$ColName}                ## Get a column you know exists
        $t-&gt;col($ColName)             ## Get a column or make empty one.
        $t-&gt;col_get($ColName)</PRE>
<PRE>
        $t-&gt;col($ColName, $ListRef)   ## Set all of a column all at once.
        $t-&gt;col_set($ColName, $ListRef)
        $t-&gt;col_force($ColName, $ListRef) ## Add but don't check size or
                                          ##  add to custom field list</PRE>
<PRE>
        $t-&gt;col_set($ColName, undef)  ## Delete a column completely
        $t-&gt;col_delete($ColName)</PRE>
<PRE>
        $t-&gt;col_empty()            ## An empty col presized for table
        $t-&gt;col_empty(22)          ## An empty col of another length
        $t-&gt;col_empty($Col)        ## An empty col sized to match another</PRE>
<PRE>
        $t-&gt;col_default()          ## Default if req. column not found.</PRE>
<PRE>
        $t-&gt;col_exists($Field)     ## Check existence of column
        $t-&gt;col_active($Field)     ## Restrict check to fieldlist()</PRE>
<PRE>
        $t-&gt;cols($ColList)         ## Get list of multiple named columns
        $t-&gt;cols_hash($ColList)    ## Get hash &quot; &quot; &quot;</PRE>
<PRE>
        $t-&gt;col_rename($Old =&gt; $New) ## Change name of columns
        $t-&gt;col_rename($Old1 =&gt; $New1, $Old2 =&gt; $New2) ## Change several</PRE>
<P>A &#147;column&#148; is a field in the table and all its data.  The column's
field name is a key in the object itself, and may also optionally be
listed in a custom field list if present.  The column's data is the
key's value in the hash and is an array ref of values presumed to be
of the same data type (e. g. string, integer, etc.)</P>
<P>Sometimes the terms &#147;column&#148; and &#147;field&#148; are used interchangeably in
this documentation.</P>
<P>If you already know that a column exists (because you got it from the
<CODE>fieldlist()</CODE> method and you've not previously manipulated _FieldList
directly but instead carefully used the method calls available for
that), then you can safely get the column by just looking it up in the
object itself.</P>
<P>The <CODE>col()</CODE> method does the same thing, but forces the column to spring
into existence if it did not already (which can also have the
potentially unwanted side-effect of hiding coding errors in which you
retreive mis-named columns: so beware).  Columns brought into
existence this way will automatically be pre-sized (i.e. they will
will be created and set to whatever <CODE>col_default()</CODE> returns).</P>
<P>The <CODE>col()</CODE> or <CODE>col_set()</CODE> methods can also be used to set a column.  When
the column is set, the list you pass is automatically sized
(lengthened or truncated) to match the current length of the table.
If this is not what you want, then call <CODE>col_force()</CODE> which will not
check whether the new column matches the size of the others.</P>
<P>No matter how you set it, the object now &#147;owns&#148; the list you gave it.</P>
<P>As a convenience, col(), <CODE>col_set()</CODE> and <CODE>col_force()</CODE> return the column
that was set.  They silently discard any previous column.</P>
<P>All three methods of column setting will append the column to the
custom field list if one is present and the column name is not already
listed there (by calling fieldlist_add()).  They will also call the
<CODE>extend()</CODE> method to ensure all columns have the same length (either
others will be extended to match the length of the new one, or the new
one will be extended to match the length of the others).</P>
<P><CODE>col_delete()</CODE> deletes a column.</P>
<P><CODE>col_empty()</CODE> returns an anonymous list reference that is pre-sized to
the length of the table (by default).  You could use it to get an
empty column that you intend to fill up and then later insert into the
table or use to hold the results of an operation on other columns.  If
you want a different length, specify it as a number or as an array ref
whose length should be matched.</P>
<P><CODE>col_default()</CODE> is the internal method that implements the ``springing
into existence'' of missing columns.  Currently it just calls
col_empty().  Other subclasses might want to have it return undef or a
string like &#147;NO_SUCH_COLUMN&#148; in order to help track programming errors
where nonexistent columns are requested.</P>
<P><CODE>cols($FieldList)</CODE> returns an ordered list of the requested column
names.  If no list is given, then <CODE>fieldlist()</CODE> is used.</P>
<P><CODE>cols_hash($FieldList)</CODE> does the same as cols(), but the result is a
hash whose keys are the field names and whose values are the columns
-- much like the original object itself, but not blessed into the
class.  The resulting hash, however, could be used as the prototype
for a new Data::CTable object (by calling the <CODE>new()</CODE> method).  However,
be warned that both objects will think they &#147;own&#148; the resulting shared
so be careful what you do..... which brings us to this:</P>
<P>IMPORTANT NOTE ABOUT GETTING COLUMNS: The columns you retrieve from a
table are still &#147;owned&#148; by the table object as long as it lives.  If
you modify them, you are modifying the table's data.  If you change
their length, then you may be invalidating the table's own
expectations that all its columns have the same length.  So beware.</P>
<P>Just make yourself a copy of the data if that isn't what you want.
For example, instead of this:</P>
<PRE>
        my $Foo =    $Table-&gt;col('Foo');   ## Reference to actual column</PRE>
<P>Do this:</P>
<PRE>
        my $Foo = [@{$Table-&gt;col('Foo')}]; ## Shallow copy of the column</PRE>
<P>
<HR>
<H1>CLEANUP AND VALIDATION</H1>
<PRE>
        ## Performing your own cleanups or validations</PRE>
<PRE>
        $t-&gt;clean($Sub)           ## Clean with custom subroutine
        $t-&gt;clean($Sub, $Fields)  ## Clean specified columns only</PRE>
<PRE>
        ## Cleaning whitespace</PRE>
<PRE>
        $t-&gt;clean_ws()        ## Clean whitespace in fieldlist() cols
        $t-&gt;clean_ws($Fields) ## Clean whitespace in specified cols</PRE>
<PRE>
        ## Cleaning methods that map character sets</PRE>
<PRE>
        $t-&gt;clean_mac_to_iso8859()
        $t-&gt;clean_mac_to_iso8859($Fields)</PRE>
<PRE>
        $t-&gt;clean_iso8859_to_mac()
        $t-&gt;clean_iso8859_to_mac($Fields)</PRE>
<PRE>
        ## Character mapping utilities (not methods)</PRE>
<PRE>
        use Data::CTable qw(
                            ISORoman8859_1ToMacRoman
                            MacRomanToISORoman8859_1</PRE>
<PRE>
                            ISORoman8859_1ToMacRoman_clean
                            MacRomanToISORoman8859_1_clean
                            );</PRE>
<PRE>
        &amp;ISORoman8859_1ToMacRoman(\ $Str)  ## Pass pointer to buffer
        &amp;MacRomanToISORoman8859_1(\ $Str)  ## Pass pointer to buffer</PRE>
<PRE>
        &amp;ISORoman8859_1ToMacRoman_clean()  ## Operates on $_
        &amp;MacRomanToISORoman8859_1_clean()  ## Operates on $_</PRE>
<P>One of the most important things you can do with your data once it's
been placed in a table in Perl is to use the power of Perl to scrub it
like crazy.</P>
<P>The built-in <CODE>clean_ws()</CODE> method applies a standard white-space cleanup
to selected records in every field in the <CODE>fieldlist()</CODE> or other list of
fields you optionally supply (such as fieldlist_all()).</P>
<P>It does the following cleanups that are deemed correct for the
majority of data out there:</P>
<PRE>
        - Remove all leading whitespace, including returns (\n)
        - Remove all trailing whitespace, including returns (\n)
        - Convert runs of spaces to a single space
        - Convert empty string values back to undef to save space</PRE>
<P>Of course, depending on your data, <CODE>clean_ws()</CODE> might just be the first
thing you do in your cleanup pass.  There might be many more cleanups
you'd like to apply.</P>
<P><CODE>clean()</CODE> is like <CODE>clean_ws()</CODE> except you supply as the first argument
your own cleaning subroutine (code reference).  It should do its work
by modifying $_.</P>
<P>Both <CODE>clean_ws()</CODE> and <CODE>clean()</CODE> apply cleaning ONLY to selected records.
If this isn't what you want, then <CODE>select_all()</CODE> before cleaning.</P>
<P>Since a cleanup subroutine can do ANY modifications to a field that it
likes, you can imagine some cleanup routines that also supply default
values and do other validations.</P>
<P>For example, a cleanup routine could convert every value in each field
to an integer, or apply minimum or maximum numerical limits:</P>
<PRE>
        sub {$_ =     int($_)      }
        sub {$_ = max(int($_), 0)  }
        sub {$_ = min(int($_), 200)}</PRE>
<P>Or your cleanup routine could use regular expressions to do
capitalizations or other regularizations of data:</P>
<PRE>
        sub Capitalize {/\b([a-z])([a-z]+)\b)/\U$1\E$2/g}</PRE>
<PRE>
        $t-&gt;clean(\ &amp;Capitalize , ['FirstName', 'LastName']);
        $t-&gt;clean(\ &amp;PhoneFormat, ['Phone', 'Fax'         ]);
        $t-&gt;clean(\ &amp;LegalUSZip,  ['HomeZip', 'WorkZip'   ]);</PRE>
<P>... and so on.  Cleanups are easy to write and quick and easy to apply
with Data::CTable.  Do them early!  Do them often!</P>
<P>
<H2>Hints for writing cleanup routines</H2>
<P>If your cleanup routine may be used to clean up fields that could be
empty/undef and empty/undef is a legal value, it should not touch any
undef values (unintentionally converting them to strings).</P>
<P>Finally, instead of setting any values to the empty string, it should
set them to undef instead.  This includes any values it might have
left empty during cleanup.  (Using undef instead of empty string to
represent empty values is one way that Data::CTable likes to save
memory in tables that may have lots of those.)</P>
<P>For an example of a well-behaved cleanup routine, consider the
following implementation of the builtin CleanWhitespace behavior:</P>
<PRE>
        sub CleanWhitespace
        {
            return unless defined;    ## Empty/undef values stay that way
            s/ \s+$//sx;              ## Remove trailing whitespace
            s/^\s+ //sx;              ## Remove leading whitespace
            s/ +/ /g;                 ## Runs of spaces to single space
            $_ = undef unless length; ## (Newly?) empty strings to undef
        }</PRE>
<P>
<H2>Roman character set mapping</H2>
<P>The character set mapping cleanup routines can be used to convert
upper-ASCII characters bidirectionally between two popular Roman
Character sets -- Mac Roman 1 and ISO 8859-1 (also sometimes called
ISO Latin 1) -- i.e. the Western European Roman character sets.</P>
<P>By default, <CODE>read()</CODE> converts all incoming data fields in data files
with Mac line endings to ISO format when reading in.  Conversely,
<CODE>write()</CODE> does the reverse mapping (ISO to Mac) when writing a file with
Mac line endings.</P>
<P>However, you may wish to turn off these default behaviors and instead
apply the mappings manually, possibly just to certain fields.</P>
<P>For example, if a table contains fields with non-Roman character sets,
you would definitely not want to apply these mappings, and instead
might want to apply some different ones that you create yourself.</P>
<P>
<H2>Utility routines for character mapping</H2>
<P>This module can optionally export four utility routines for mapping
character Latin 1 character sets.  Always be sure to map the correct
direction -- otherwise you'll end up with garbage!  Be careful to only
pass Western Roman strings -- not double-byte strings or strings
encoded in any single-byte Eastern European Roman or non-Roman
character set.</P>
<PRE>
        &amp;ISORoman8859_1ToMacRoman(\ $Str)  ## Pass pointer to buffer
        &amp;MacRomanToISORoman8859_1(\ $Str)  ## Pass pointer to buffer</PRE>
<P>These routines translate characters whose values are 128-255 from one
Western Roman encoding to another.  The argument is a string buffer of
any size passed by reference.</P>
<P>The functions return a count of the number of characters that were
mapped (zero or undef if none were).</P>
<PRE>
        &amp;ISORoman8859_1ToMacRoman_clean()  ## Operates on $_
        &amp;MacRomanToISORoman8859_1_clean()  ## Operates on $_</PRE>
<P>These routines are variants of the above, but they're versions that
are compatible with <CODE>clean()</CODE> -- they operate on $_ and will take care
to leave undefined values undefined.  They do not have return values.</P>
<P>
<H2>More advanced cleaning and validation</H2>
<P>Unfortunately, <CODE>clean()</CODE> only lets you operate on a single field value
at a time -- and there's no way to know the record number or other
useful information inside the cleaning routine.</P>
<P>For really powerful cleaning and validation involving access to all
fields of a record as well as record numbers, see the discussion of
the <CODE>calc()</CODE> method and other methods for doing complex field
calculations in the next section.</P>
<P>
<HR>
<H1>CALCULATIONS USING <CODE>calc()</CODE></H1>
<PRE>
        ## Calculate a new field's values based on two others</PRE>
<PRE>
        $t-&gt;calc($Sub)              ## Run $Sub for each row, with 
                                    ##  fields bound to local vars</PRE>
<PRE>
        $t-&gt;calc($Sub,  $Sel)           ## Use these row nums
        $t-&gt;calc($Sub, undef, $Fields)  ## Use only these fields
        $t-&gt;calc($Sub,  $Sel, $Fields)  ## Use custom rows, fields</PRE>
<PRE>
        my $Col = $t-&gt;calc($Sub)    ## Gather return vals in vector</PRE>
<PRE>
        ## Example 1: Overwrite values in an existing column.</PRE>
<PRE>
        $t-&gt;calc(sub{no strict 'vars'; $Size = (stat($Path))[7]});</PRE>
<PRE>
        ## Example 2: Create empty column; fill fields 1 by 1</PRE>
<PRE>
        $t-&gt;col('PersonID');
        $t-&gt;calc(sub{no strict 'vars'; $PersonID = &quot;$Last$First&quot;});</PRE>
<PRE>
        ## Example 3: Calculate values; put into to table if desired</PRE>
<PRE>
        $PersonID = $t-&gt;calc(sub{no strict 'vars'; &quot;$Last$First&quot;});
        $t-&gt;sel('PersonID', $PersonID);</PRE>
<PRE>
        ## Example 4: Using fully-qualified variable names</PRE>
<PRE>
        $t-&gt;calc(sub{$main::PersonID = &quot;$main::Last$main::First&quot;});</PRE>
<P><CODE>calc()</CODE> runs your custom calculation subroutine $Sub once for every row
in the current <CODE>selection()</CODE> or other list of row numbers that you
specify in the optional $Sel argument.</P>
<P>This lets you apply a complex calculation to every record in a table
in a single statement, storing the results in one or more columns, or
retrieving them as a list.</P>
<P>Your custom subroutine may refer to the value in any field in the
current row by using a global variable with the field's name:</P>
<P>For example, if the table has fields First, Last, and Age, then $Sub
may use, modify, and set the variables $First, $Last, $Age.  (Also
known as $main::First, $main::Last, $main::Age).</P>
<P>Modifying any of these specially-bound variables actually modifies the
data in the correct record and field within the table.</P>
<P>By default, the fields available to $Sub are all fields in the table.
<CODE>calc()</CODE> must bind all the field names for you for each row, which can
be time-consuming for tables with very large numbers of fields.</P>
<P>You can speed up the operation of <CODE>calc()</CODE> by listing only the fields
your $Sub needs in the optional parameter $Fields.  Any field names
you don't mention won't be available to $Sub.  Conversely, <CODE>calc()</CODE> will
run faster because it can bind only the fields you actually need.</P>
<P>If you include non-existent fields in your custom $Fields list, <CODE>calc()</CODE>
creates them for you before $Sub runs the first time.  Then your $Sub
can store field values into the new column, referring to it by name.</P>
<P>Variables in $Sub are in the &#147;main&#148; package.  So you should set $Sub
to use pacakge &#147;main&#148; in case the rest of your code is not in &#147;main&#148;.</P>
<P>Similarly, if you &#147;use strict&#148;, Perl will complain about global
variables in $Sub.  So you may need to assert &#147;no strict 'vars'&#148;.</P>
<PRE>
        {   package Foo; use strict;
</PRE>
<PRE>

            $t = ...;
            $t-&gt;calc(sub {package main; no strict 'vars'; 
                          $Age = int($Age)});
        }</PRE>
<PRE>
        ## Or this:</PRE>
<PRE>
        {   package Foo;  use strict;</PRE>
<PRE>
            $t = ...;
            {   package main; no strict 'vars';
                my $Sub = sub {$Age = int($Age)};
            }
            $t-&gt;calc($Sub);
        }</PRE>
<P>You may be able to get around both problems more easily by prefixing
each variable reference in $Sub with &#147;main::&#148;.  This takes care of the
package name issue and bypasses &#147;use strict&#148; at the same time, at the
slight cost of making the calculation itself a bit harder to read.</P>
<PRE>
        $t-&gt;calc(sub {$main::Age = int($main::Age)}); ## OK in any package</PRE>
<P>In addition to the field names, the following three values are defined
during each invocation of $Sub:</P>
<PRE>
        $_r ($main::_r) -- the row number in the entire table
        $_s ($main::_s) -- the item number in selection or $Recs
        $_t ($main::_t) -- the table object itself</PRE>
<P>You could use these values to print diagnostic information or to
access any of the data, parameters, or methods of the table itself
from within $Sub.  Or you could even calculate field values using $_r
or $_s.</P>
<P>For example, after searching &amp; sorting, you could make a field which
preserves the resulting sort order for future reference:</P>
<PRE>
        $t-&gt;col('Ranking');      ## Create the empty column first.
        $t-&gt;calc(sub{$main::Ranking = $main::_s});</PRE>
<P>This last example is equivalent to:</P>
<PRE>
        $t-&gt;sel(Ranking =&gt; [0 .. $#{$t-&gt;selection()}]); ## See sel() below</PRE>
<P>
<HR>
<H1>&#147;MANUAL&#148; CALCULATIONS</H1>
<P><CODE>calc()</CODE> (see previous secion) is the briefer, more elegant way to do
batch calculations on entire columns in a table, but it can be
slightly slower than doing the calculations yourself.</P>
<P>If you have extremely large tables, and you notice the processing time
for your calculations taking more than a second, you might want to
rewrite your calculations to use the more efficient techniques shown
here.</P>
<P>You will often need to create new calculated columns based on one or
more existing ones, and then either insert the columns back in the
tables or use them for further calculations or indexing.</P>
<P>Examples 1a and 1b create a new field 'NameOK' containing either the
string &#147;OK&#148; or undef (empty) depending on whether the field 'Name' is
empty.  Just use <CODE>map()</CODE> to iterate over the existing values in the
other column, binding $_ to each value in turn.</P>
<PRE>
        ### Example 1a: Calculation based on one other column</PRE>
<PRE>
        ## Retrieve column
        my $Name    = $t-&gt;col('Name');
</PRE>
<PRE>

        ## Make new column
        my $NameOK  = [map {!!length &amp;&amp; 'OK'} @$Name];</PRE>
<PRE>
        ## Insert column back into table:
        $t-&gt;col(NameOK =&gt; $NameOK);</PRE>
<PRE>
        ### Example 1b: Same calculation, in a single statement:</PRE>
<PRE>
        $t-&gt;col(NameOK =&gt; [map {!!length &amp;&amp; 'OK'} @{$t-&gt;col('Name')}]);</PRE>
<P>In order to iterate over MULTIPLE columns at once, you need a list of
the row numbers generated by $t-&gt;<CODE>all()</CODE> so you can index the two
columns in tandem.  Then, you use map to bind $_ to each row number,
and then use the expression $t-&gt;col($ColName)-&gt;[$_] to retreive each
value.</P>
<P>Examples 2a and 2b demonstrate this method.  They create a new field
'FullName' which is a string joining the values in the 'First' and
'Last' columns with a space between.</P>
<PRE>
        ### Example 2a: Calculation based on multiple columns</PRE>
<PRE>
        ## Retrieve columns
        my $First = $t-&gt;col('First');  
        my $Last  = $t-&gt;col('Last' );</PRE>
<PRE>
        ## Retreive row nums
        my $Nums  = $t-&gt;all();</PRE>
<PRE>
        ## Calculate a new column based on two others
        my $Full  = [map {&quot;$First-&gt;[$_] $Last-&gt;[$_]&quot;} @$Nums];</PRE>
<PRE>
        ## Add new column to the table
        $t-&gt;col(FullName =&gt; $Full);</PRE>
<PRE>
        ### Example 2b: Same calculation, in a single statement:</PRE>
<PRE>
        $t-&gt;col(FullName =&gt; 
                [map {&quot;$t-&gt;col('First')-&gt;[$_] t-&gt;col('Last')-&gt;[$_]&quot;} 
                 @{$t-&gt;all()}]);</PRE>
<P>In examples 1 and 2, you create entirely new columns and then add or
replace them in the table.</P>
<P>Using the approach in Examples 3a and 3b, you can assign calculated
results directly into each value of an existing column as you go.</P>
<PRE>
        ## Example 3a: Calculate by assigning directly into fields...</PRE>
<PRE>
        my $A = $t-&gt;col-&gt;('A'); ## This column will be modified
        my $B = $t-&gt;col-&gt;('B');
        my $C = $t-&gt;col-&gt;('C');</PRE>
<PRE>
        foreach @($t-&gt;all()) {$A-&gt;[$_] = $B-&gt;[$_] + $C-&gt;[$_];}</PRE>
<PRE>
        ## Example 3b: Same calculation, in a single statement:</PRE>
<PRE>
        foreach @($t-&gt;all()) {($t-&gt;col('A')-&gt;[$_] =
                               $t-&gt;col('B')-&gt;[$_] + 
                               $t-&gt;col('C')-&gt;[$_])};</PRE>
<P>Before writing your code, think about which calculation paradigms best
suit your needs and your data set.</P>
<P>Just as Perl Hackers know: There's More Than One Way To Do It!</P>
<P>
<HR>
<H1>INDEXES</H1>
<PRE>
        ## Make indexes of columns or just selected data in columns</PRE>
<PRE>
        my $Index1 = $t-&gt;index_all($Key);  ## entire column
        my $Index2 = $t-&gt;index_sel($Key);  ## selected data only</PRE>
<PRE>
        ## Make hashes of 2 columns or just selected data in columns</PRE>
<PRE>
        my $Index1 = $t-&gt;hash_all($KeyFld, $ValFld);  ## entire column
        my $Index2 = $t-&gt;hash_sel($KeyFld, $ValFld);  ## selected data</PRE>
<P><CODE>index_all()</CODE> creates and returns a hash (reference) that maps keys
found in the column called $Key to corresponding record numbers.</P>
<P>Ideally, values in $Key would be unique (that's up to you).</P>
<P>If any values in $Key are NOT unique, then later values (higher record
numbers) will be ignored.</P>
<P><CODE>index_sel()</CODE> creates and returns a hash (ref) that maps keys found in
the SELECTED RECORDS of column $Key to corresponding record numbers.</P>
<P>Any keys in unselected records are ignored.  Otherwise, the behavior
is equivalent to index_all().</P>
<P><CODE>hash_all()</CODE> and <CODE>hash_sel()</CODE> are similar, except they create and return
hashes whose keys are taken from column $KeyFld, but whose values are
from $ValFld in the corresponding records.</P>
<P>So, for example, imagine you have a tab-delimited file on disk with
just a single tab per line (2 fields) and no header row.  The entries
on the left side of the tab on each line are keys and the right side
are values.  You could convert that file into a hash in memory like
this:</P>
<PRE>
        my $t = Data::CTable-&gt;new({_HeaderRow=&gt;0, _FieldList=&gt;[qw(F1 F2)]}, 
                                  &quot;DeptLookup.txt&quot;);</PRE>
<PRE>
        my $DeptLookup = $t-&gt;hash_all(qw(F1 F2));</PRE>
<P>
<H2>Reverse indexes</H2>
<P>If you'd like an index mapping record number to key, just get
$t-&gt;col($Key).  That's what the data columns in Data::CTable are.</P>
<P>
<HR>
<H1>DATA ROWS (RECORDS)</H1>
<PRE>
        ## Getting or setting rows / records</PRE>
<PRE>
        $t-&gt;row($Num)             ## Get a row or make empty one.
        $t-&gt;row_get($Num)</PRE>
<PRE>
        $t-&gt;row($Num, $HashRef)   ## Set all of a row all at once.
        $t-&gt;row_set($Num, $HashRef)</PRE>
<PRE>
        $t-&gt;row_set($Num, undef)  ## Delete a row completely
        $t-&gt;row_delete($Num)      
        $t-&gt;row_delete($Beg, $End)## Delete a range of rows</PRE>
<PRE>
        $t-&gt;row_move($Old, $New)   ## Move a row to before $New</PRE>
<PRE>
        $t-&gt;row_empty()            ## An empty hash
        $t-&gt;row_exists($Num)       ## True if $Num &lt; $t-&gt;length()</PRE>
<PRE>
        $t-&gt;rows($RowList)         ## Get list of multiple row nums</PRE>
<PRE>
        $t-&gt;row_list($Num)          ## Get row vals as a list
        $t-&gt;row_list($Num, $Fields) ## Get row vals: specified fields</PRE>
<PRE>
        $t-&gt;row_list_set($Num, undef, $Vals)   ## Set row vals as a list
        $t-&gt;row_list_set($Num, $Fields, $Vals) ## Set row vals as a list
        $t-&gt;row_list_set($Num, $Fields)        ## Set vals to empty/undef</PRE>
<P>Usually, when working with Data::CTable objects, you are operating on
entire columns or tables at a time (after all: any transformation you
do on one record you almost always want to do on all records or all
selected ones).</P>
<P>You should very rarely need to access data by retrieving rows or
setting rows, moving them around individually, and so on.  (It's much
cleaner, and much more efficient to manipulate the <CODE>selection()</CODE> (list
of selected row numbers) instead -- just delete a row number from the
selection, for example, and then for most operations it's almost as if
the row is gone from the table, except the data is really still
there.)</P>
<P>However, if on rare occasions you really do need direct row
operations, you're reading the right section.</P>
<P>A row is generally accessed as a hash.  The hash you provide or get
back is not saved by the object in any way.  Data values are always
copied in or out of it, so you always &#147;own&#148; the hash.</P>
<P>Rows are specified by $Num -- the row number with in the unsorted
columns (the raw data in the table).  These numbers are just array
indices into the data columns, and so their legal range is:</P>
<PRE>
        [0 .. ($t-&gt;length() - 1)]     ##   (Zero-based row numbering.)</PRE>
<P>The row hash (or &#147;record&#148;) has keys that are field names and values
that are copies of the scalar values stored in the data columns within
the table.</P>
<P><CODE>row()</CODE> always copies only the fields in fieldlist(), except for
<CODE>row_list()</CODE> which allows you to specify an optional $Fields parameter
which can override the current fieldlist().</P>
<P>If the fieldlist happens to be a subset of all fields, but you really
want to get all fields in your record, then call <CODE>fieldlist_set(0)</CODE>
first to permanently or temporarily delete it.</P>
<P><CODE>row()</CODE> and <CODE>row_get()</CODE> always return a hash.</P>
<P>row($Num, $Hash), <CODE>row_set()</CODE> take a hash and set just the fields you
specify in the hash (in the given row of course).  Any non-existent
field names in the hash are created, so be careful.</P>
<P>In fact, in general with either getting or setting rows, any
non-existent fields mentioned will be created for you (by internally
calling col()).  So you could build a whole table of 100 rows by
starting with an empty, new, table and setting row 99 from a hash that
gives the field names.</P>
<P>Setting a row number higher than any existing row number with row(),
<CODE>row_set()</CODE> or <CODE>row_force()</CODE> will automatically set the new length of the
entire table to match (extending all the columns with empty rows as
necessary).</P>
<P>IMPORTANT: IF YOU SIMPLY MUST ADD ROWS SEQUENTIALLY, do not let the
table auto-extend by one with each row you set.  This is slow and gets
rapidly slower if there's lots of data because the arrays holding the
data columns will keep getting reallocated on every insert.  Instead,
first pre-extend the table to your highest row number by calling
length($Len), and then set your rows.  Or easier: if convenient just
set your rows starting with the highest-numbered one first.  If you
don't know how many you'll have, guess or estimate and pre-extend to
the estimated number and then cut back later.  This will be faster
than extending all columns by one each time.</P>
<P><CODE>row_delete()</CODE> removes a row or range of rows completely from the table.
Any rows above the deleted ones will move down and the table's
<CODE>length()</CODE> will decrease.  If the data columns are very large, this
could be a bit slow because a lot of data could be moved around.  The
low and high row numbers will be limited for you to 0 and <CODE>length()</CODE> -
1, respectively.  Null ranges are OK and are silently ignored.  The
range is inclusive, so to delete just row 99, call <CODE>row_delete(99)</CODE> or
row_delete(99,99).</P>
<P>EFFICIENCY NOTE: Don't call <CODE>row_delete()</CODE> to remove lots of individual
rows.  Instead, select those row numbers by setting the selection (if
not already selected), and then invert the selection using
selection_invert(), so the undesired rows are deselected, and then use
the <CODE>cull()</CODE> method to rewrite the entire table at once.  The deselected
rows will be omitted very efficiently this way.</P>
<P><CODE>row_move()</CODE> moves a row from its $Old row number to the position before
the row currently in row $New (specify $New = <CODE>length()</CODE> to move the row
to the end).  Again, in shuffling data in columns, lots of data could
get moved around by this operation, so expect it to be slow.  If as
with row_delete(), if you will be doing several moves, consider
building an appropriate <CODE>selection()</CODE> first, and then using <CODE>cull()</CODE>
instead.</P>
<P>Using <CODE>row_delete()</CODE> and <CODE>row_move()</CODE> to shift records around changes the
record numbers of the affected records and many others in the table.
The record numbers in the custom selection, if any, are updated to
reflect these changes, so the records that were selected before will
still be selected after the move (except those that were deleted of
course).  If you had a private copy of the selection, your copy will
likely become outdated after these operations.  You should get it
again by calling selection().</P>
<P><CODE>row_empty()</CODE> returns a hash whose keys are the entries in <CODE>fieldlist()</CODE>
and whose values are undef.  (You could use it to fill in values
before calling row_set()).  Note: in this class, <CODE>row_empty()</CODE> does
exactly the same thing as <CODE>fieldlist_hash()</CODE> when the latter is called
with no arguments.</P>
<P><CODE>row_exists()</CODE> returns true if <CODE>(($Num &gt;= 0) &amp;&amp; ($Num &lt; $t-&gt;length()))</CODE>.</P>
<P><CODE>rows()</CODE> calls <CODE>row()</CODE> for each row num in a list and returns a list of
the resulting hashes.</P>
<P><CODE>row_list()</CODE> gets row values as a list instead of a hash.  They appear
in the order specified in <CODE>fieldlist()</CODE> unless you supply an optional
$Fields parameter listing the fields you want to get.</P>
<P><CODE>row_list_set()</CODE> sets row values as a list instead of a hash.  Pass your
own $Fields list or undef and <CODE>fieldlist()</CODE> will be used.  $Values
should be a list with the same number of values as fields expected;
any shortage will result in undef/empty values being set.</P>
<P>
<HR>
<H1>ROW / RECORD COUNT (TABLE LENGTH)</H1>
<PRE>
        ## Getting or setting table length</PRE>
<PRE>
        $t-&gt;length()        ## Get length
        $t-&gt;length_get()</PRE>
<PRE>
        $t-&gt;length(22)      ## Set length (truncate or pre-extend)
        $t-&gt;length_set(22)</PRE>
<PRE>
        $t-&gt;extend()        ## Set length of all columns to match longest</PRE>
<P>The length* methods assume the table already has columns of equal
length.  So the length of the table is the length of any field taken
at random.  We choose the first one in the field list.</P>
<P>Setting the length will truncate or pre-extend every column in the
table to a given length as required.</P>
<P>(Pre-extending means setting each column's length via $# so that it
has the correct number of entries already allocated (and filled with
undef) so that operations that fill up the table can be done much more
quickly than with push().</P>
<P>However, if a new column has been added directly, or a table has been
constructed out of columns whose length may not initially match, the
<CODE>extend()</CODE> method may be (should be) called to inspect all columns and
extend them all to match the longest one.  Note that <CODE>extend()</CODE> operates
on all fields in the object, ignoring the custom _FieldList if any.</P>
<P>The length of a table with no columns is zero.</P>
<P>
<HR>
<H1>SELECTIONS</H1>
<PRE>
        ## Getting or setting the custom selection list itself (_Selection)</PRE>
<PRE>
        $t-&gt;selection()               ## Get sel if any; else all()
        $t-&gt;selection_get()</PRE>
<PRE>
        $t-&gt;selection($List)          ## Set sel (list of rec nums)
        $t-&gt;selection_set($List)
</PRE>
<PRE>

        $t-&gt;selection(0)              ## Remove sel (select all)
        $t-&gt;selection_set(undef)      
        $t-&gt;selection_delete()
        $t-&gt;select_all()</PRE>
<PRE>
        $t-&gt;selection_inverse()       ## Get inverse copy of selection
        $t-&gt;select_inverse()          ## Invert the selection</PRE>
<PRE>
        $t-&gt;selection_validate()      ## Remove invalid #s from sel</PRE>
<PRE>
        ## List of all rec nums present (regardless of selection)</PRE>
<PRE>
        $t-&gt;all()</PRE>
<PRE>
        ## Getting or setting just selected fields in columns
        ## (as contrasted with col() and friends).</PRE>
<PRE>
        $t-&gt;sel($ColName)             ## Get col but only records in sel
        $t-&gt;sel_get($ColName)</PRE>
<PRE>
        $t-&gt;sel($ColName, $ListRef)   ## Set selected fields in col...
        $t-&gt;sel_set($ColName, $ListRef) ##... in selection order</PRE>
<PRE>
        $t-&gt;sel_set($ColName)         ## Set selected fields to undef
        $t-&gt;sel_clear($ColName)</PRE>
<PRE>
        $t-&gt;sels($ColList)            ## Like cols, but selected fields
        $t-&gt;sels_hash($ColList)       ## &quot; &quot;   cols_hash()... &quot; &quot; &quot; &quot;</PRE>
<PRE>
        ## Finding out size of selection (number of rows)</PRE>
<PRE>
        $t-&gt;sel_len()                 ## Get number of selected rows.</PRE>
<P>A selection is an ordered list of record numbers.  The record numbers
in the selection may be a subset of available records.  Furthermore,
they may be in non-record-number order, indicating that the records
have been sorted.</P>
<P>Record numbers are numeric array indices into the columns in the
table.  It is an error for any selection list to contain an index less
than zero or greater than (length() - 1), so if you set a selection
explicitly, be careful.</P>
<P>Any selection list you get or set belongs to the object.  Be careful
of modifying its contents.</P>
<P>The custom selection, if any, is stored internally in the _Selection
parameter.  If this parameter is absent, the selection defaults to
<CODE>all()</CODE> -- i.e. a list of all record numbers, in order:
[0..($this-&gt;<CODE>length()</CODE> - 1)] (which becomes [] if <CODE>length()</CODE> is 0).</P>
<P>REMEMBER: <CODE>length()</CODE> is one-based, but record numbers are zero-based.</P>
<P>Removing the selection (that is, removing the LIST itself of which
records are selected), is the same as selecting all records.
consequently, selection(0), selection_delete(), and <CODE>select_all()</CODE> are
all synonymous.</P>
<P><CODE>selection_validate()</CODE> removes any entries from the current _Selection
list (if any) that are not valid record numbers -- i.e. it removes any
record whose integer value is &lt; 0 or greater than <CODE>length()</CODE> - 1.  This
routine is mainly used by other methods that might delete records,
such as length_set().</P>
<P>Getting or setting just selected data from columns</P>
<P>Sometimes, you don't want to get/set entire columns, you instead want
to get or set data in just the selected fields in a column.</P>
<P>The sel(), sel_get(), sel_set(), <CODE>sels()</CODE> and <CODE>sels_hash()</CODE> methods are
analagous to the corresponding col(), ... <CODE>cols_hash()</CODE> methods except
in these two ways:</P>
<P>- the 'sels' variants get or set just selected data, as determined by
the current selection(), which gives an ordered list of the selected /
sorted records.</P>
<P>- the 'sels' variants all make COPIES of the data you request or
supply -- the data is copied out of or into the correspnding column.
So, you &#147;own&#148; any vector you pass or receive in reply.</P>
<P>So, for example, imagine you have just set <CODE>selection()</CODE> to only list
record numbers where the LastName field is not empty.  Then you have
called <CODE>sort()</CODE> to sort those record numbers by the LastName field.  You
could then call $t-&gt;<CODE>sel('LastName')</CODE> to get a sorted list of all
non-empty last names.</P>
<P>It might be helpful to think of &#147;sel&#148; as short for &#147;selected&#148;.  So
$t-&gt;<CODE>sel('LastName')</CODE> would mean ``get the selected field values from the
LastName field''.</P>
<P>
<HR>
<H1>SEARCHING / SELECTING RECORDS</H1>
<PRE>
        ## Modifying the table's custom selection (_Selection)</PRE>
<PRE>
        $t-&gt;select_all()      ## Set _Selection = $t-&gt;all() or undef
        $t-&gt;select_none()     ## Set _Selection = []
        $t-&gt;select_inverse()  ## Invert the curr. sel. (and get it)</PRE>
<PRE>
        ## Specific searches: &quot;the select() methods&quot;</PRE>
<PRE>
        $t-&gt;select($Field1=&gt;$Sub1, ## Del nonmatching recs from sel.
                   $Field2=&gt;$Sub2, ## i.e. narrow sel. to match
                   ...);</PRE>
<PRE>
        $t-&gt;omit  ($Field1=&gt;$Sub1, ## Del matching recs from sel.
                   $Field2=&gt;$Sub2, 
                   ...);</PRE>
<PRE>
        $t-&gt;add   ($Field1=&gt;$Sub1, ## Add matching recs to sel.
                   $Field2=&gt;$Sub2,    
                   ...);</PRE>
<PRE>
        $t-&gt;but   ($Field1=&gt;$Sub1, ## Add nonmatching recs to sel.
                   $Field2=&gt;$Sub2,    
                   ...);</PRE>
<PRE>
        ## Getting useful lists of record numbers...</PRE>
<PRE>
        $t-&gt;all()                  ## Get &quot;full&quot; sel. (all record #s)
        $t-&gt;selection()            ## Get current selection
        $t-&gt;selection_inverse()    ## Get inverse copy of curr. sel.</PRE>
<PRE>
        ## Example 1: Refine a selection by narrowing down...</PRE>
<PRE>
        $t-&gt;select_all()
        $t-&gt;select(Field1 =&gt; sub {$_});
        $t-&gt;select(Field2 =&gt; sub {$_});
        $t-&gt;select(Field3 =&gt; sub {$_});</PRE>
<PRE>
        ## Example 2: Manually refine and set the selection...</PRE>
<PRE>
        $Sel = [grep {$t-&gt;col($Field1)-&gt;[$_]} @{$t-&gt;all      ()}];
        $Sel = [grep {$t-&gt;col($Field2)-&gt;[$_]} @$Sel];
        $Sel = [grep {$t-&gt;col($Field3)-&gt;[$_]} @$Sel];
        $t-&gt;selection($Sel);    ## Set the selection when done.</PRE>
<PRE>
        ## Example 3: Complex manual search using calculated value
</PRE>
<PRE>

        my $A = $t-&gt;col('A');
        my $B = $t-&gt;col('B');
        my $S = [grep 
                 {my $X = $A-&gt;[$_] + $B-&gt;[$_]; ($X &gt; 100 &amp;&amp; $X &lt; 200);} 
                 @{$t-&gt;all()}]; ## Or could start with $t-&gt;selection().
        $t-&gt;selection($S);      ## Set the selection when done.</PRE>
<PRE>
        ## Example 4: Refine a selection by building up...</PRE>
<PRE>
        $t-&gt;select_none()
        $t-&gt;add(Field1 =&gt; sub {$_});
        $t-&gt;add(Field2 =&gt; sub {$_});
        $t-&gt;add(Field3 =&gt; sub {$_});</PRE>
<PRE>
        ## Example 5: Combining the select() methods to build a query...</PRE>
<PRE>
        $t-&gt;select_all()
        $t-&gt;select(Status  =&gt; sub {/prime/i   });
        $t-&gt;omit  (DueDate =&gt; sub {$_ &gt; $Today});
        $t-&gt;add   (Force   =&gt; sub {$_         });</PRE>
<P><CODE>select()</CODE> and its friends omit(), add(), and but(), known collectively
as &#147;the <CODE>select()</CODE> methods,&#148; all work similarly: they take a series of
one or more pairs indicating matches to be done, where each match is
specified as (FieldName =&gt; Subroutine).</P>
<P>In addition to the field names already present in the table, the
FieldName in any Spec may also be one of these two special
pseudo-fields:</P>
<DL>
<DT><STRONG>_RecNum</STRONG><BR>
<DD>
the record number of the record being compared
<P></P>
<DT><STRONG>_SelNum</STRONG><BR>
<DD>
the numerical position of the record being compared within the
previous selection (only usable with <CODE>select()</CODE> and <CODE>omit()</CODE> since <CODE>add()</CODE>
and <CODE>but()</CODE> by definition operate on non-selected records).
<P></P></DL>
<P>For example:</P>
<PRE>
        ## Match 2nd 100 rec numbers
        $t-&gt;select(_RecNum =&gt; sub {$_ &gt;= 100 &amp;&amp; $_ &lt;= 199});</PRE>
<PRE>
        ## Match 2nd 100 currently selected/sorted items
        $t-&gt;select(_SelNum =&gt; sub {$_ &gt;= 100 &amp;&amp; $_ &lt;= 199});</PRE>
<P>Be careful when using _SelNum in a search. In the above _SelNum search
example, since the selection itself will be modified by select(), the
items that were formerly selection items 100 - 199 will now be _SelNum
0 - 99 in the new selection.</P>
<P>The Subroutine is an anonymous grep-style predicate that operates on
$_ and should return true/false to indicate a match with an element of
the field FieldName.</P>
<P>The order of multiple matches in a single method call is significant
only in that the searches can be faster if the field that will match
the fewest records is listed first.</P>
<P>A given FieldName may be listed in the specs more than once if it has
multiple search criteria that you prefer to execute as multiple
subroutines (though it would be more efficient on very large tables to
combine their logic into one subroutine joined with &#147;&amp;&amp;&#148;).</P>
<P>Each field match will be applied (with an implied AND joining them) to
determine whether the record itself matches.  Then, based on whether
the record itself matches, it will either be added or deleted from the
selection based on which method is being called:</P>
<PRE>
        method...  operates on...     action....
        ------------------------------------------------------------------
        select()   selected records   Keep only recs that DO     match
        omit()     selected records   Keep only recs that DO NOT match
        add()      non-selected recs  Add       recs that DO     match
        but()      non-selected recs  Add       recs that DO NOT match</PRE>
<P>Here's how to think about what's going on:</P>
<PRE>
        methods... think...
        ------------------------------------------------------------------
        select()   &quot;SELECT things matching this&quot;...
        omit()     &quot;... then OMIT those matching this.&quot;</PRE>
<PRE>
        select()   &quot;SELECT things matching this&quot;...
        add()      &quot;... and ADD any others matching this.&quot;</PRE>
<PRE>
        select()   &quot;SELECT things matching this&quot;...
        but()      &quot;... and add any others BUT those matching this.&quot;</PRE>
<P><CODE>select()</CODE> and <CODE>omit()</CODE> both NARROW the selection.</P>
<P><CODE>add()</CODE> and <CODE>but()</CODE> both INCREASE the selection.</P>
<P>IMPORTANT: You DO NOT need to use these <CODE>select()</CODE> routines to work with
selections.  It may be much easier for you to clarify your logic, or
more efficient to express your search, using a single grep or series
of grep operations as in Examples 2 or 3 above.</P>
<P>Building the selection manually is required if you want to filter
based on any COMPLEX RELATIONSHIPS BETWEEN FIELDS.  For example, if
you want to add two fields and match or reject the record based on the
sum of the fields.</P>
<P>In Example 3 above, we add the values in fields &#147;A&#148; and &#147;B&#148; and then
match the record only if the SUM is between 100 and 199.  By grepping
to produce a subset of @{$t-&gt;all()}, you end up with a Selection -- a
list of record numbers you want &#147;selected&#148;.  Then you call
$t-&gt;<CODE>selection()</CODE> to put the selection you built into the object.</P>
<P>If you had instead wanted to narrow an existing selection in the above
example, you would start with $t-&gt;<CODE>selection()</CODE> (which defaults to
$t-&gt;<CODE>all())</CODE> instead of starting with $t-&gt;all().</P>
<P>Each of the <CODE>select()</CODE> methods returns $this-&gt;<CODE>selection()</CODE> as a
convenience.</P>
<P>
<H2>The effects of modifying a sorted selection</H2>
<P>Generally, you should sort AFTER finding, and you should not generally
rely on sort order after doing a find.  But in case you want to know,
the following chart explains what happens to the sort order after the
various <CODE>select()</CODE> commands are called (at least in the current
implementation, which may change without notice):</P>
<PRE>
        method... effect on an existing sort order...
        ------------------------------------------------------------------
        select()  relative sort order is preserved (stay sorted)
        omit()    all selected recs restored to &quot;natural&quot; order (unsorted)
        add()     orig. recs preserved; new recs appended: &quot;natural&quot; order
        but()     orig. recs preserved; new recs appended: &quot;natural&quot; order</PRE>
<P>In other words, you could <CODE>sort()</CODE> first and then call <CODE>select()</CODE> to
narrow down the selection repeatedly without disrupting the sort
order.  However, any of the other methods will disrupt the sort order
and you would need to re-sort.  The preservation of order when using
select(), and other sort order effects, are likely but not guaranteed
to be preserved in future implementations.</P>
<P>
<H2>Hints about Boolean logic</H2>
<P>Consider the following example and the alternative below it.  You
might initially think these are equivalent, but they're not:</P>
<PRE>
        ## Case 1:</PRE>
<PRE>
        my $Sel = $t-&gt;add(Force  =&gt; sub {$_ == 1      });
        my $Sel = $t-&gt;add(Status =&gt; sub {$_ eq 'Prime'});</PRE>
<PRE>
        ## Case 2:</PRE>
<PRE>
        my $Sel = $t-&gt;add(Force  =&gt; sub {$_ == 1      },
                          Status =&gt; sub {$_ eq 'Prime'});</PRE>
<P>Case 1 extends the selection by adding all records where Force == 1,
and then extends it again by adding all additional records where
Status eq 'Prime'.</P>
<P>Case 2 adds only those records where: Force == 1 AND ALSO, IN THE SAME
RECORD, Status eq 'Prime'.</P>
<P>One final note about logic.  This is not SQL and these <CODE>select()</CODE> etc.
routines are not meant to replace the full power of a programming
language.</P>
<P>If you want full Boolean expressions, use the power of Perl to form
your own arbitrarily complex query using grep as in Example 3 above.</P>
<P>Writing your own grep is also almost always faster than chaining the
builtin <CODE>select()</CODE> methods or using multiple Field / Sub specifications,
so keep that in mind when working with extremely large data sets.</P>
<P>With tables of only a few thousand records or so, you probably won't
notice the difference in efficiency.</P>
<P>
<HR>
<H1>SORTING</H1>
<PRE>
        ## Sort the current table's _Selection</PRE>
<PRE>
        $t-&gt;sort()                       ## Use existing/default params
        $t-&gt;sort([qw(Last First Phone)]) ## Specify _SortOrder (fields)
        $t-&gt;sort(                        ## Named-parameter call:
                 _SortOrder =&gt; [...],    ##  override sort-related params.
                 _Selection =&gt; [...],    ##  (See param lists above).
                 _SortSpecs =&gt; {...},
                 _SRoutines =&gt; {...},
                 _DefaultSortType=&gt;'Integer',
                 _DefaultSortDirection=&gt;-1,
                 );</PRE>
<P>The <CODE>sort()</CODE> method modifies the _Selection (creating one with all
records if it was missing, undef, or not supplied by caller) so that
the record numbers listed there are sorted according to the criteria
implied by _SortOrder, _SortSpecs, _SRoutines, etc.</P>
<P>For example, before sorting, a table's &#147;natural&#148; order might be:</P>
<PRE>
        Rec# First  Last Age State
        0    Chris  Zack 43  CA
        1    Marco  Bart 22  NV
        2    Pearl  Muth 15  HI</PRE>
<P>... and its <CODE>selection()</CODE> method would yield: [0, 1, 2] -- which is a
list of all the records, in order.</P>
<P>After calling $t-&gt;sort([Last]), <CODE>selection()</CODE> would yield [1, 2, 0].  So
displaying the table in &#147;selection&#148; order would yield:</P>
<PRE>
        Rec# First  Last Age State
        1    Marco  Bart 22  NV
        2    Pearl  Muth 15  HI
        0    Chris  Zack 43  CA</PRE>
<P>IMPORTANT: sorting does not alter any data in the table.  It merely
alters the _Selection parameter (which you can then get and set using
the <CODE>selection()</CODE> methods described above).</P>
<P>If you want to permanently alter the table's data in memory so that
the new sorted order becomes the &#147;natural&#148; order, you can use the
<CODE>cull()</CODE> method to modify the original object, the <CODE>snapshot()</CODE> method to
make a new object, or use the <CODE>write()</CODE> method to write the data to disk
in selected/sorted order and then <CODE>read()</CODE> it back again.</P>
<P>
<H2>Using the Named-parameter calling convention with <CODE>sort()</CODE></H2>
<P>You may specify any combination of the parameters listed above when
calling sort().  Any you specify will be used IN PLACE OF the
corresponding parameters already found in the object.</P>
<P>If you specify _Selection using the named-parameter calling, the
<CODE>sort()</CODE> method reserves the right to &#147;own&#148; the list you provide, and
use it as the object's new _Selection, possibly discarding the
previous _Selection, if any and modifying the one you provided.  So
don't make any assumptions about ownership of that list object after
calling sort().  Luckily, you will rarely need to provide _Selection
explicitly since generally you'll want to be sorting the <CODE>selection()</CODE>
already inherent in the object.</P>
<P><CODE>sort()</CODE> returns the _Selection list owned by the object (the same list
that would be returned if you called the <CODE>selection()</CODE> method
immediately after calling sort()).</P>
<P>See the next sections for complete descriptions of _SortOrder and
other sorting parameters.</P>
<P>
<HR>
<H1>SORT ORDER</H1>
<PRE>
        ## Getting / Setting table's default _SortOrder</PRE>
<PRE>
        $t-&gt;sortorder()         ## Get sortorder (default is [])
</PRE>
<PRE>

        my $Order = [qw(Last First State Zip)];
        $t-&gt;sortorder($Order)   ## Set sortorder (use [] for none)</PRE>
<PRE>
        $t-&gt;sortorder_default() ## Get the object's default sort order ([])</PRE>
<P>The sort order is an optional list of field names on which to sort and
sub-sort the data when sorting is requested.  The field names must be
the names of actual columns in the table.  The names in the sort order
do not necessarily need to coincide with the custom fieldlist if any.</P>
<P>There is one special value that can be included: _RecNum.  This sorts
on the imaginary &#147;record number&#148; field.  So for example, you could
specify a sort order this way:</P>
<PRE>
        [qw(Last First _RecNum)]</PRE>
<P>(There is no point in putting _RecNum anywhere except at the end of
the sort order because no two records will ever have the same record
number so there will be no further need to disambiguate by referring
to additional fields.)</P>
<P>Sorting by _RecNum adds a bit of computational overhead because <CODE>sort()</CODE>
first builds a record number vector for use in sorting, so for very
large tables, don't do it unless you really need it.</P>
<P>A sort order can be specified each time the object is sorted (see the
<CODE>sort()</CODE> method for details).</P>
<P>Or, the object's sort order can be set once, and then <CODE>sort()</CODE> will use
that sort order when no other sort order is specified.</P>
<P>If sorting is done when there is no sort order present in the object
or specifed for the <CODE>sort()</CODE> method, the selection is sorted by record
number (i.e. it is &#147;unsorted&#148; or returned to its &#147;natural&#148; order).</P>
<P>In order words, a sortorder that is undef or [] is considered the same
as: [qw(_RecNum)].  This is sometimes called &#147;unsorting&#148;.</P>
<P>In order to decide how values in each field should be compared, <CODE>sort()</CODE>
is informed by SortSpecs (specifying SortType and SortDirection for
each field) and by SortRoutines, each of which may similarly either be
pre-set for the object or specified when calling <CODE>sort()</CODE> -- see below
for further details.</P>
<P>
<HR>
<H1>SORT SPECIFICATIONS</H1>
<PRE>
        ## Getting / Setting table's default _SortSpecs</PRE>
<PRE>
        $t-&gt;sortspecs()         ## Get sortspecs (default is {} -- none)</PRE>
<PRE>
        my $Specs = {Last =&gt; {SortType       =&gt; 'String' , 
                              SortDirection  =&gt; -1        },
                     Zip  =&gt; {SortType       =&gt; 'Integer' }};</PRE>
<PRE>
        $t-&gt;sortspecs($Specs)   ## Set sortspecs</PRE>
<PRE>
        $t-&gt;sortspecs_default() ## Get the object's default sort specs ({})</PRE>
<P>The sortspecs are an optional hash mapping field names to ``sort
specifications''.</P>
<P>Each field's sort specification may specify zero or more of these
values:</P>
<DL>
<DT><STRONG>SortType</STRONG><BR>
<DD>
the sort type to use (For example: String, Integer)
<P></P>
<DT><STRONG>SortDirection</STRONG><BR>
<DD>
the sort direction (1: ascending, -1: descending)
<P></P></DL>
<P>Sortspecs can be specified when calling the <CODE>sort()</CODE> routine, or, a set
of specs can be placed beforehand into the object itself and those
will be used by <CODE>sort()</CODE> if no other specs are given.</P>
<P>For any field listed in the sort order at the time of sorting, but
lacking a sort spec or any component of the sort spec, the object's
default sort type (see <CODE>sorttype_default())</CODE> and default sort direction
(see <CODE>sortdirection_default())</CODE> will be used.</P>
<P>In addition to getting/setting sort specs as a whole, they may be
gotten/set on a per-field basis, too:</P>
<PRE>
        sortspec($Field)       ## Get sortspec for $Field or default spec</PRE>
<PRE>
        my $Spec   = {SortType =&gt; 'Integer', SortDirection =&gt; -1};
        sortspec('Zip', $Spec) ## Set sortspec</PRE>
<PRE>
        sortspec_default()     ## Get a sortspec with all defaults filled in</PRE>
<P>For any $Field not found in the object's sortspecs, <CODE>sortspec($Field)</CODE>
returns the same thing returned by sortspec_default(), which is a
sortspec filled in with the default sort type and sort direction (see
below).</P>
<P>For a list of available built-in SortTypes, and instructions for how
to define your own, see SORT ROUTINES, below.</P>
<P>
<HR>
<H1>DEFAULT SORT DIRECTION</H1>
<PRE>
        ## Getting / Setting table's default _DefaultSortDirection</PRE>
<PRE>
        $t-&gt;sortdirection_default()     ## Get default sort direction</PRE>
<PRE>
        $t-&gt;sortdirection_default(-1)   ## Set default sort direction</PRE>
<P>Each element in a sort specification can optionally specify a sort
direction.</P>
<P>1 = ascending, -1 = descending</P>
<P>For any sort specs that don't specify a direction, the object's
default sort direction will be used.  Use these routines to get/set
the default sort direction.</P>
<P>
<HR>
<H1>DEFAULT SORT TYPE</H1>
<PRE>
        ## Getting / Setting table's default _DefaultSortType</PRE>
<PRE>
        $t-&gt;sorttype_default()          ## Get default sort type</PRE>
<PRE>
        $t-&gt;sorttype_default('Integer') ## Set default sort type</PRE>
<P>Each element in a sort specification can optionally specify a sort
type.  The sort type is a string (like 'String' or 'Integer' or
'Date') that selects from one or more sort routines.  (See Sort
Routines, below).</P>
<P>There are several sort routines built into the CTable object, and you
can also add as many of your own routines (and hence Sort Types) as
you like or need.  This allows for very flexible sorting.</P>
<P>For any sort specs that don't specify a type, the object's default
sort type will be used.  Use these routines to get/set the default
sort type, which initially is 'String'.</P>
<P>
<HR>
<H1>SORT ROUTINES: BUILTIN AND CUSTOM</H1>
<PRE>
        ## Getting / Setting table's custom sort routines (_SRoutines)</PRE>
<PRE>
        $t-&gt;sortroutine($Type)       ## Get a sort routine for $Type</PRE>
<PRE>
        $t-&gt;sortroutine($Type, $Sub) ## Set a sort routine for $Type</PRE>
<PRE>
        $t-&gt;sortroutine($Type, 0   ) ## Remove sort routine for $Type
        $t-&gt;sortroutine_set($Type)
</PRE>
<PRE>

        $t-&gt;sortroutines()           ## Get hash of any sort routines</PRE>
<PRE>

        $t-&gt;sortroutines_builtin()   ## Get hash of builtin routines</PRE>
<P>Each SortType in the sortspecs should have a corresponding sort
routine (any unrecognized type will be sorted using the 'String' sort
routine).</P>
<P>The <CODE>sort()</CODE> command looks up the appropriate sort routine for each
field it is asked to sort, based on the SortType for that field, as
given in the sortspecs, as described above.</P>
<P>Builtin sort types, recognized and implemented natively by this
module, are:</P>
<PRE>
        String   ## Fastest case-sensitive compare (data is string)
        Text     ## Insensitive compare (lowercases, then compares)
        Number   ## Number works for floats or integers
        Integer  ## Faster than floats.  Uses &quot;use integer&quot;
        DateSecs ## Same as integer; assumes date in seconds
        Boolean  ## Treats item as a Perlish boolean (empty/undef = false)</PRE>
<P>The above sort types are always recognized.  Additional sort types may
be added by subclasses (and could shadow the builtin implementations
of the above types if desired) and/or may be added to instances (and
again could shadow the above implementations), and/or may be specified
when the <CODE>sort()</CODE> method is called, once again optionally shadowing any
deeper definitions.</P>
<P>
<HR>
<H1>CUSTOM SORT ROUTINE INTERFACE</H1>
<P>A custom sort routine is called with two arguments, each of which is a
pointer to a scalar.  The sort routine should dereference each pointer
and compare the resulting scalars, returning -1 if the first scalar is
smaller than the second, 1 if it is larger, and 0 if they are
considered equal.</P>
<P>For example, here is the built-in comparison routine for 'String':</P>
<PRE>
        sub {   $ {$_[0]}  cmp    $ {$_[1]} }</PRE>
<P>NOTE: Your custom sort routines should NOT compare $a and $b as with
Perl's builtin <CODE>sort()</CODE> command.</P>
<P>Examine the variable $BuiltinSortRoutines in this module's
implementation to see some additional examples of sort routines.</P>
<P>Internally, <CODE>sort()</CODE> calls the <CODE>sortroutines()</CODE> method to get a hash that
should consist of all builtin sort routines with the per-object sort
routines, if any, overlaid.  <CODE>sortroutines()</CODE> in turn calls the
<CODE>sortroutines_builtin()</CODE> method to get a copy of the hash of all builtin
sort routines for the object.  (So a subclass could easily add
additional SortTypes or reimplement them by just overriding
<CODE>sortroutines_builtin()</CODE> and adding its own additional routines to the
resulting hash.)</P>
<P><CODE>sortroutine()</CODE> may be called to get or set a custom sort routine for a
given type in the given object.</P>
<P>There is no way to directly manipulate the builtin sort routines for
the entire class.  To accomplish that, you should define and use a
subclass that extends <CODE>sortroutines_builtin()</CODE> to add its own routines.</P>
<P>For example:</P>
<PRE>
        BEGIN
        {   ## A subclass of Data::CTable with an INetAddr SortType.
            package IATable;    use vars qw(@ISA);    @ISA = qw(Data::CTable);</PRE>
<PRE>
            sub sortroutines_builtin
            {
                my $this = shift;
                my $CustomRoutines = 
                {INetAddr =&gt; 
                 sub {use integer; ip2int($ {$_[0]}) &lt;=&gt; ip2int($ {$_[1]})}};
                my $AllRoutines = 
                {%{$this-&gt;SUPER::sortroutines_builtin()} %$CustomRoutines};
                return($AllRoutines);
            };</PRE>
<PRE>
            sub ip2int {.....}  $# Could memoize &amp; inline for efficiency
        }</PRE>
<PRE>
        my $Table = IATable::new(......);</PRE>
<P>The IATable class would then have all the same features of
Data::CTable but would then also support the INetAddr SortType.</P>
<P>
<HR>
<H1>FREEZING SELECTION &amp; FIELD LIST</H1>
<PRE>
        ## Freeze data layout: re-order columns; omit unused fields
</PRE>
<PRE>

                $t-&gt;cull(...params...)     ## Rebuild table in order
        my $s = $t-&gt;snapshot(...params...) ## Make copy as if rebuilt</PRE>
<P>The <CODE>cull()</CODE> method re-writes all data in the table to be in the order
indicated in _Selection (if present).  This will cause any records not
listed in _Selection to be omitted (unless selection is null in which
case all records are retained in original order).</P>
<P>In addition, if there is a custom field list present, it removes any
fields NOT mentioned in _FieldList.</P>
<P>The <CODE>snapshot()</CODE> method is similar, except instead of modifying the
object itself, it makes a copy of the object that's equivalent to what
<CODE>cull()</CODE> would have created, and returns that new object, leaving the
original untouched.  (All data structures are deep-copied from the old
object to the new one, leaving the objects totally independent.)</P>
<P><CODE>cull()</CODE> and <CODE>snapshot()</CODE> both take two optional named parameters:
_FieldList and/or _Selection to be used in place of the corresponding
parameters found in the object.</P>
<P>If only a single argument is supplied, it is assumed to be _Selection.</P>
<P>
<HR>
<H1>LINE ENDINGS</H1>
<PRE>
        ## Get current value</PRE>
<PRE>
        $t-&gt;lineending()          ## Get actual setting: string or symbol
        $t-&gt;lineending_symbol()   ## Get setting's symbolic value if possible
        $t-&gt;lineending_string()   ## Get setting's string value if possible</PRE>
<PRE>
        ## Set value</PRE>
<PRE>
        $t-&gt;lineending($Ending)   ## Will be converted internally to symbol</PRE>
<PRE>
        ## Convert a value to symbol or string form</PRE>
<PRE>
        $t-&gt;lineending_symbol($L) ## Convert string form to symbolic form
        $t-&gt;lineending_string($L) ## Convert symbol form to string form</PRE>
<PRE>
        ## Get internal conversion hash tables</PRE>
<PRE>
        $t-&gt;lineending_symbols()  ## Hash ref mapping known strings to symbols
        $t-&gt;lineending_strings()  ## Hash ref mapping known symbols to strings</PRE>
<P>Use these accessor functions to get/set the _LineEnding parameter.</P>
<P>You can set the parameter in either string or symbol form as you wish.
You can get it in its raw, as-stored, form, or, you can get it in
string form or symbol form as desired.</P>
<P>Finally, some utility conversion calls allows you to convert a string
you have on hand to a symbolic form.  For example:</P>
<PRE>
        $L = &quot;\x0D&quot;;
        print (&quot;This file uses &quot; . $t-&gt;lineending_symbol($L) . &quot; endings.&quot;);</PRE>
<P>This would print:
</P>
<PRE>

        This file uses mac endings.</PRE>
<P>
<HR>
<H1>AUTOMATIC CACHEING</H1>
<P>By default, Data::CTable makes cached versions of files it reads so it
can read them much more quickly the next time.  Optionally, it can
also cache any file it writes for quicker re-reading later.</P>
<P>On Unix systems, cache files are always created with 0666
(world-write) permissions for easy cleanup.</P>
<P>When reading files, Data::CTable checks the _CacheOnRead parameter.
If that parameter is true, which it is by default, the module tries to
find an up-to-date cache file to read instead of the original.
Reading a cache file can be 10x faster than reading and parsing the
original text file.</P>
<P>In order to look for the cache file, it must first calculate the path
where the cache file should be located, based on the _FileName of the
file to be read.</P>
<P>The path of the cache file is calculated as follows:</P>
<P>If the _CacheSubDir parameter is a RELATIVE PATH, then it is appended
to the directory component of _FileName to arrive at the directory to
use to store the cache file.  If it is an ABSOLUTE PATH, then
_CacheSubDir is used by itself.  (The trailing path separator is
optional and an appropriate one will be added by Data::CTable if it is
missing.)</P>
<P>The file name of the cache file is calculated as follows:</P>
<P>If the _CacheExtension parameter is specified, it is appended to the
base file name component from the _FileName parameter.  If you want
the cached file name to be the same as the name of the original file,
you can set _CacheExtension to ``'', which is not recommended.</P>
<P>Then, the cache path and cache file name are joined to arrive at the
name of the cache file.  If both _CacheSubDir and _CacheExtension were
empty, then the cache file path will be the same as the _FileName, and
Data::CTable will refuse to either read or write a cache file, so
setting these fields both to empty is equivalent to setting
_CacheOnRead to false.</P>
<P>The cache file contains a highly-efficient representation of all the
following data that would otherwise have to be determined by reading
and parsing the entire text file:</P>
<PRE>
        - All the data columns (field values)
        - _FieldList:  The list of fields, in order
        - _HeaderRow:  Whether a header row is / should be present
        - _LineEnding: The line ending setting
        - _FDelimiter: The field delimiter setting</PRE>
<P>If found prior to a read(), AND, the date of the cache file is LATER
than the date of the original file, the cache file is used instead.
(If the date is EARLIER, then the cache file is ignored because it can
be presumed that the data inside the text file is newer.)</P>
<P>If cacheing is ON, then after successfully reading the text file
(either because there was no cache file yet or the cache file was out
of date or corrupted or otherwise unusable), <CODE>read()</CODE> will then try to
create a cache file.  This, of course, takes some time, but the time
taken will be more than made up in the speedup of the next <CODE>read()</CODE>
operation on the same file.</P>
<P>If creating the cache file fails (for example, because file
permissions didn't allow the cache directory to be created or the
cache file to be written), <CODE>read()</CODE> generates a warning explaining why
cacheing failed, but the <CODE>read()</CODE> operation itself still succeeds.</P>
<P>No parameters in the object itself are set or modified to indicate the
success or failure of writing the cache file.</P>
<P>Similarly, there is no way to tell whether a successful <CODE>read()</CODE>
operation read from the cache or from the original data file.  If you
want to be SURE the reading was from the data file, either turn off
_CacheOnRead, or call the <CODE>read_file()</CODE> method instead of read().</P>
<P>NOTE: because the name of the cache file to be used is calculated just
before the <CODE>read()</CODE> is actually done, the cache file can only be found
if the _CacheSubDir and _CacheExtension are the same as they were when
the cache was last created.  If you change these parameters after
having previously cached a file, the older caches could be &#147;orphaned&#148;
and just sit around wasting disk space.</P>
<P>
<H2>Cacheing on <CODE>write()</CODE></H2>
<P>You may optionally set _CacheOnWrite (default = false) to true.  If
done, then a cache file will be saved for files written using the
<CODE>write()</CODE> command.  Read about <CODE>write()</CODE> below for more about why you
might want to do this.</P>
<P>
<HR>
<H1>AUTOMATIC DIRECTORY CREATION</H1>
<P>When Data::CTable needs to write a file, (a cache file or a data
file), it automatically tries to create any directories or
subdirectories you specify in the _FileName or _CacheSubDir
parameters.</P>
<P>If it fails while writing a data file, <CODE>write()</CODE> will fail (and you will
be warned).  If it fails to create a directory while writing a cache
file, a warning will be issued, but the overall <CODE>read()</CODE> or <CODE>write()</CODE>
operation will still return a result indicating success.</P>
<P>Any directories created will have the permissions 0777 (world-write)
for easy cleanup.</P>
<P>Generally, the only directory the module will have to create is a
subdirectory to hold cache files.</P>
<P>However, since other directories could be created, be sure to exercise
caution when allowing the module to create any directories for you on
any system where security might be an issue.</P>
<P>Also, if the 0666 permissions on the cache files themselves are too
liberal, you can either 1) turn off cacheing, or 2) call the
<CODE>prep_cache_file()</CODE> method to get the name of the cache file that would
have been written, if any, and then restrict its permissions:</P>
<PRE>
        chmod (0600, $this-&gt;prep_cache_file());</PRE>
<P>
<HR>
<H1>READING DATA FILES</H1>
<PRE>
        ## Replacing data in table with data read from a file</PRE>
<PRE>
        $t-&gt;read($Path)     ## Simple calling convention</PRE>
<PRE>
        $t-&gt;read(           ## Named-parameter convention</PRE>
<PRE>
             ## Params that override params in the object if supplied...</PRE>
<PRE>
             _FileName      =&gt; $Path, ## Full or partial path of file to read</PRE>
<PRE>
             _FieldList     =&gt; [...], ## Fields to read; others to be discarded</PRE>
<PRE>
             _HeaderRow     =&gt; 0,     ## No header row (_FieldList required!)</PRE>
<PRE>
             _LineEnding    =&gt; undef, ## Text line ending (undef means guess)
             _FDelimiter    =&gt; undef, ## Field delimiter (undef means guess)</PRE>
<PRE>
             _ReturnMap     =&gt; 1,     ## Whether to decode internal returns
             _ReturnEncoding=&gt;&quot;\x0B&quot;, ## How to decode returns.
             _MacRomanMap   =&gt; undef, ## Whether/when to read Mac char set</PRE>
<PRE>
             _CacheOnRead   =&gt; 0,     ## Enable/disable cacheing behavior
             _CacheExtension=&gt; &quot;.x&quot;,  ## Extension to add to cache file name
             _CacheSubDir   =&gt; &quot;&quot;,    ## (Sub-)dir, if any, for cache files</PRE>
<PRE>
             ## Params specific to the read()/write() methods...</PRE>
<PRE>
             _MaxRecords    =&gt; 200,   ## Limit on how many records to read
             )</PRE>
<PRE>
        $t-&gt;read_file()     ## Internal: same as read(); ignores cacheing</PRE>
<P><CODE>read()</CODE> opens a Merge, CSV, or Tab-delimited file and reads in all or
some fields, and all or some records, REPLACING ANY EXISTING DATA in
the CTable object.</P>
<P>Using the simple calling convention, just pass it a file name.  All
other parameters will come from the object (or will be defaulted if
absent).  To specify additional parameters or override any parameters
in the object while reading, use the named-parameter calling
convention.</P>
<P>See the full PARAMETER LIST, above, or read on for some extra details:</P>
<P>_ReturnMap controls whether return characters encoded as ASCII 11
should be mapped back to real newlines (<CODE>&quot;\n&quot;</CODE>) when read into memory.
If false, they are left as ASCII 11 characters. (default is &#147;true&#148;)</P>
<P>_ReturnEncoding controls the character that returns are encoded as, if
different from ASCII 11.</P>
<P>_FieldList is an array (reference) listing the names of fields to
import, in order (and will become the object's _FieldList upon
successful completion of the <CODE>read()</CODE> operation).  If not provided and
not found in the object, or empty, then all fields found in the file
are imported and the object's field list will be set from those found
in the file, in the order found there.  If _HeaderRow is false, then
this parameter is required (either in the object or as a formal
parameter) and is assumed to give the correct names for the fields as
they actually occur in the file.  If _HeaderRow is true and _FieldList
is provided, then _FieldList specifies the (sub-)set of fields to be
read from the file and others will be ignored.</P>
<P>_HeaderRow, which defaults to true, if set to false, tells <CODE>read()</CODE> to
not expect a header row showing the field names in the file.  Instead,
it assumes that the _FieldList gives those (and _FieldList must
therefore be specified either as a parameter or an existing parameter
in the object).</P>
<P>_MaxRecords (optional) is an upper limit on the number of fields to
import.  If not specified, or zero, or undef, then there is no limit;
all records will be imported or memory will be exhausted.</P>
<P><CODE>read()</CODE> returns a Boolean &#147;success&#148; code.</P>
<P>If <CODE>read()</CODE> returns false, then it will also have set the _ErrorMsg
parameter in the object.  It may or may not have partially altered
data in the object if an error is encountered.</P>
<P>After a successful read:</P>
<P><CODE>fieldlist()</CODE> (the object's _FieldList parameter) tells which
fields were actually read, in what order.  It may omit any fields
requested in _FieldList that were not actually found in the file for
whatever reason.</P>
<P><CODE>length()</CODE> tells how many fields were read.</P>
<P>The <CODE>selection()</CODE> is reset to no selection (all selected / unsorted)</P>
<P>The object's _FileName parameter contains the path to the file
that was read.  If the _FileName you specified did not have a path,
then _FileName will be prepended with a path component indicating
&#147;current directory&#148; (e.g. &#147;./&#148; on Unix).</P>
<P>_FDelimiter will contain the actual delimiter character that was
used to read the file (either tab or comma if the delimiter was
guessed, or whatever delimiter you specified).</P>
<P>_LineEnding will contain the actual line-ending setting used to
read the file.  This will be either &#147;mac&#148; (&#147;\x0D&#148;), &#147;unix&#148; (&#147;\x0D&#148;),
or &#147;dos&#148; (&#147;\x0D\x0A&#148;) if the line endings were guessed by read().
Otherwise it will be whatever _LineEnding you specified.</P>
<P>
<HR>
<H1>FILE FORMAT NOTES</H1>
<P>As mentioned, <CODE>read()</CODE> allows the following flexibilities in reading
text-based tabular data files:</P>
<P>You may specify the line endings (record delimiters), or it can
guess them (mac, unix, dos are supported).</P>
<P>You may specify the field delimiters, or it can guess them (tab
and comma are supported).</P>
<P>It can get field names from a header row, or, if there is no
header row, you can tell it the field names, in order.</P>
<P>You can tell it whether or not to decode embedded returns in
data fields, and if so, which character they were encoded as.</P>
<P>Beyond supporting the above flexible options, <CODE>read()</CODE> makes the
following non-flexible assumptions:</P>
<P>Fields must NOT contain unencoded returns -- that is: whatever
character sequence is specified for _LineEnding will NEVER occur
inside a field in the text file; in addition, the current platform's
definition of <CODE>&quot;\n&quot;</CODE> will NEVER occur; these characters if present in
field data, MUST have been encoded to some safe character string
before the file was created.</P>
<P>Each field may OPTIONALLY be surrounded with double-quote marks.
However, if the field data itself contains either a double-quote
character (<CODE>&quot;</CODE>) or the current file's field delimiter (such as tab or
comma), then the field MUST be surrounded with double-quotes.
(Currently, all data written by Data::CTable have all field values
surrounded by double-quotes, but a more selective policy may be used
in the future.)</P>
<P>If a field contains a double-quote character, then each double-quote
character in the field must be encoded as <CODE>&quot;&quot;</CODE> -- i.e. each <CODE>&quot;</CODE> in the
original data becomes <CODE>&quot;&quot;</CODE> in the text file.</P>
<P>Data files may not mix line-ending types or field delimiter types.
Once determined, the same endings and delimiters will be used to read
the entire file.</P>
<P>The fields recognized on each line will either be determined by
the header row or the _FieldList provided by the caller.  Any extra
fields on any given line will be ignored.  Any missing fields will be
treated as undef/empty.</P>
<P>If you are having trouble reading a delimited text file, check that
all data in the file obeys these assumptions.</P>
<P>
<HR>
<H1>WRITING DATA FILES</H1>
<PRE>
        ## Writing some or all data from table into a data file</PRE>
<PRE>
        $t-&gt;write($Path)              ## Simple calling convention</PRE>
<PRE>
        $t-&gt;write(                    ## Named-parameter convention</PRE>
<PRE>
             ## Params that override params in the object if supplied...</PRE>
<PRE>
             _FileName      =&gt; $Path, ## &quot;Base path&quot;; see _WriteExtension</PRE>
<PRE>
             _WriteExtension=&gt; &quot;.out&quot;,## Insert/append extension to _FileName</PRE>
<PRE>
             _FieldList     =&gt; [...], ## Fields to write; others ignored
             _Selection     =&gt; [...], ## Record (#s) to write; others ignored</PRE>
<PRE>
             _HeaderRow     =&gt; 0,     ## Include header row in file</PRE>
<PRE>
             _LineEnding    =&gt; undef, ## Record delimiter (default is &quot;\n&quot;)
             _FDelimiter    =&gt; undef, ## Field delimiter (default is comma)</PRE>
<PRE>
             _ReturnMap     =&gt; 1,     ## Whether to encode internal returns
             _ReturnEncoding=&gt;&quot;\x0B&quot;, ## How to encode returns
             _MacRomanMap   =&gt; undef, ## Whether/when to write Mac char set</PRE>
<PRE>
             _CacheOnWrite  =&gt; 1,     ## Enable saving cache after write()
             _CacheExtension=&gt; &quot;.x&quot;,  ## Extension to add to cache file name
             _CacheSubDir   =&gt; &quot;&quot;,    ## (Sub-)dir, if any, for cache files</PRE>
<PRE>
             ## Params specific to the read()/write() methods...</PRE>
<PRE>
             _MaxRecords    =&gt; 200,   ## Limit on how many records to write
             )</PRE>
<PRE>
        $t-&gt;write_file()    ## Internal: same as write(); ignores cacheing</PRE>
<P><CODE>write()</CODE> writes a Merge, CSV, or Tab-delimited file.</P>
<P>It uses parameters as described above.  Any parameters not supplied
will be gotten from the object.</P>
<P>Using the simple calling convention, just pass it a path which will
override the _FileName parameter in the object, if any.</P>
<P>All other parameters will come from the object (or will be defaulted
if absent).</P>
<P>If no _FileName or path is specified, or it is the special string &#147;-&#148;
(dash), then the file handle \ * STDOUT will be used by default (and
you could redirect it to a file).  You can supply any open file handle
or IO::File object of your own for the _FileName parameter.</P>
<P>If <CODE>write()</CODE> is writing to a file handle by default or because you
specified one, then no write-cacheing will occur.</P>
<P>To specify additional parameters or override any parameters in the
object while reading, use the named-parameter calling convention.</P>
<P>If the object's data was previously filled in using <CODE>new()</CODE> or read(),
then the file format parameters from the previous <CODE>read()</CODE> method will
still be in the object, so the format of the written file will
correspond as much as possible to the file that was read().</P>
<P><CODE>write()</CODE> returns the path name of the file actually written, or the
empty string if a supplied file handle or STDOUT was written to, or
undef if there was a failure.</P>
<P>If <CODE>write()</CODE> returns undef, then it will also have set the _ErrorMsg
parameter in the object.</P>
<P><CODE>write()</CODE> never modifies any data in the object itself.</P>
<P>Consequently, if you specify a _FieldList or a _Selection, only those
fields or records will be written, but the corresponding parameters in
the object itself will be left untouched.</P>
<P>
<H2>How <CODE>write()</CODE> calculates the Path</H2>
<P>The _FileName parameter is shared with the <CODE>read()</CODE> method.  This
parameter is set by <CODE>read()</CODE> and may be overridden when calling write().</P>
<P>In the base implementation of Data::CTable, <CODE>write()</CODE> will try not to
overwrite the same file that was read, which could possibly cause data
loss.</P>
<P>To avoid this, it does not use the _FileName parameter directly.
Instead, it starts with _FileName and inserts or appends the value of
the _WriteExtension parameter (which defaults to &#147;.out&#148;) into the file
name before writing.</P>
<P>If the _FileName already has an extension at the end, <CODE>write()</CODE> will
place the _WriteExtension BEFORE the final extension; otherwise the
_WriteExtension will be placed at the end of the _FileName.</P>
<P>For example:</P>
<PRE>
        Foobar.txt        ==&gt;  Foobar.out.txt
        Foobar.merge.txt  ==&gt;  Foobar.merge.out.txt
        My_Merge_Data     ==&gt;  My_Merge_Data.out</PRE>
<P>If you DON'T want <CODE>write()</CODE> to add a _WriteExtension to _FileName before
it writes the file, then you must set _WriteExtension to empty/undef
either in the object or when calling write().  Or, you could make a
subclass that initializes _WriteExtension to be empty.  If
_WriteExtension is empty, then _FileName will be used exactly, which
may result in overwriting the original data file.</P>
<P>Remember: <CODE>write()</CODE> returns the path name it actually used to
successfully write the file.  Just as with read(), if the _FileName
you specified did not have a path, then <CODE>write()</CODE> will prepend a path
component indicating &#147;current directory&#148; (e.g. &#147;./&#148; on Unix) and this
will be part of the return value.</P>
<P>
<H2>Cacheing with <CODE>write()</CODE></H2>
<P>By default, Data::CTable only creates a cached version of a file when
it reads that file for the first time (on the assumption that it will
need to read the file again more often than the file's data will
change.)</P>
<P>But by default, it does not create a cached version of a file when
writing it, on the assumption that the current program probably will
not be re-reading the written file and any other program that wants to
read it can cache it at that time.</P>
<P>However, if you want <CODE>write()</CODE> to create a cache for its output file, it
is much faster to create it on <CODE>write()</CODE> than waiting for the next
<CODE>read()</CODE> because the next <CODE>read()</CODE> will be able to use the cache the very
first time.</P>
<P>To enable write-cacheing, set _CacheOnWrite to true.  Then, after the
<CODE>write()</CODE> successfully completes (and only if it does), the cached
version will be written.</P>
<P>
<HR>
<H1>FORMATTED TABLES (Using Data::ShowTable)</H1>
<PRE>
        ## Get formatted data in memory</PRE>
<PRE>
        my $StringRef = $t-&gt;format();     ## Format same data as write()
        my $StringRef = $t-&gt;format(10);   ## Limit records to 10
        my $StringRef = $t-&gt;format(...);  ## Specify arbitrary params
        print $$StringRef;</PRE>
<PRE>
        ## Write formatted table to file or terminal</PRE>
<PRE>
        $t-&gt;out($Dest, ....);## $Dest as follows; other params to format()
        $t-&gt;out($Dest, 10, ....) ## Limit recs to 10; params to format()</PRE>
<PRE>
        $t-&gt;out()            ## print formatted data to STDOUT
        $t-&gt;out(\*STDERR)    ## print to STDERR (or any named handle)
        $t-&gt;out(&quot;Foo.txt&quot;)   ## print to any path (file to be overwritten)
        $t-&gt;out($FileObj)    ## print to any object with a print() method</PRE>
<P><CODE>out()</CODE> takes a first argument specifying a destination for the output,
then passes all other arguments to <CODE>format()</CODE> to create a nice-looking
table designed to be human-readable; it takes the resulting buffer and
print()s it to the destination you specified.</P>
<P>Sample output:</P>
<PRE>
         +-------+------+-----+-------+
         | First | Last | Age | State |
         +-------+------+-----+-------+
         | Chris | Zack | 43  | CA    |
         | Marco | Bart | 22  | NV    |
         | Pearl | Muth | 15  | HI    |
         +-------+------+-----+-------+</PRE>
<PRE>
        (Note extra space character before each line.)</PRE>
<P>The destination may be a file handle (default if undef is \*STDOUT), a
string (treated as a path to be overwritten), or any object that has a
<CODE>print()</CODE> method, especially an object of type IO::File.</P>
<P>The main purpose of <CODE>out()</CODE> is to give you a quick way to dump a table
when debugging.  <CODE>out()</CODE> calls <CODE>format()</CODE> to create the output, so read
on...</P>
<P><CODE>format()</CODE> produces a human-readable version of a table, in the form of
a reference to a string buffer (which could be very large), and
returns the buffer to you.  Dereference the resulting string reference
before using.</P>
<P>If <CODE>format()</CODE> is given one argument, that argument is the _MaxRecords
parameter, which limits the length of the output.</P>
<P>Otherwise, <CODE>format()</CODE> takes the following named-parameter arguments,
which can optionally override the corresponding parameters, if any, in
the object:</P>
<PRE>
        _FieldList        ## Fields to include in table
        _Selection        ## Records to be included, in order</PRE>
<PRE>
        _SortSpecs        ## SortType controls number formatting
        _DefaultSortType</PRE>
<PRE>
        _MaxRecords       ## Limit number of records output</PRE>
<PRE>
        _MaxWidth         ## Limit width of per-col. data in printout</PRE>
<P><CODE>format()</CODE> will obey _MaxRecords, if you'd like to limit the number of
rows to be output.  _MaxRecords can also be a single argument to
format(), or a second argument to <CODE>out()</CODE> if no other parameters are
passed.</P>
<P><CODE>format()</CODE> also recognizes the _SortSpecs-&gt;{SortType} and
_DefaultSortType parameters to help it determine the data types of the
fields being formatted.  Fields of type &#147;Number&#148; are output as
right-justified floats; &#147;Integer&#148; or &#147;Boolean&#148; are output as
right-justified integers, and all others (including the default:
String) are output as left-justified strings.</P>
<P>In addition, there is one parameter uniquely supported by <CODE>format()</CODE> and
out():</P>
<DL>
<DT><STRONG>_MaxWidth  ||= 15;</STRONG><BR>
<DD>
</DL>
<P>_MaxWidth specifies the maximum width of columns.  If unspecifed, this
will be 15; the minimum legal value is 2.  Each column may actually
take up 3 more characters than _MaxWidth due to divider characters.</P>
<P>The data to be output will be examined, and only the necessary width
will be used for each column.  _MaxWidth just limits the upper bound,
not the lower.</P>
<P>Data values that are too wide to fit in _MaxWidth spaces will be
truncated and the tilde character &#147;~&#148; will appear as the last
character to indicate the truncation.</P>
<P>Data values with internal returns will have the return characters
mapped to slashes for display.</P>
<P><CODE>format()</CODE> and <CODE>out()</CODE> will NOT wrap entries onto a second line,
like you may have seen Data::ShowTable::ShowBoxTable do in some cases.
Each record will get exactly one line.</P>
<P><CODE>format()</CODE> and <CODE>out()</CODE> ignore the _HeaderRow parameter.  A header
row showing the field names is always printed.</P>
<P><CODE>format()</CODE> and <CODE>out()</CODE> make no attempt to map upper-ascii characters from
or to any particular dataset.  The encoding used in memory (generally
ISO 8859-1 by default) is the encoding used in the output.  If you
want to manipulate the encoding, first call format(), then change the
encoding, then format the resulting table.</P>
<P>
<HR>
<H1>APPENDING / MERGING / JOINING TABLES</H1>
<PRE>
        ## Append all records from a second table</PRE>
<PRE>
        $t-&gt;append($Other)                ## Append records from $Other
        $t-&gt;append_file($File, $Params)   ## Append from new($Params, $File)
        $t-&gt;append_files($Files, $Params) ## Call append_file for all files
        $t-&gt;append_files_new($Files, $Params) ## Internal helper routine</PRE>
<PRE>
        ## Combine all fields from a second table</PRE>
<PRE>
        $t-&gt;combine($Other)                ## Combine fields from $Other
        $t-&gt;combine_file($File, $Params)   ## Combine new($Params, $File)
        $t-&gt;combine_files($Files, $Params) ## combine_file on each file</PRE>
<PRE>
        ## Left-join records from a second table (lookup field vals)</PRE>
<PRE>
        $t-&gt;join      ($Other,          $KeyField1, [$KeyField2, $Fields]) 
        $t-&gt;join_file ($File,  $Params, $KeyField1, [$KeyField2, $Fields])
        $t-&gt;join_files($Files, $Params, $KeyField1, [$KeyField2, $Fields])</PRE>
<P>The <CODE>append()</CODE> method concatenates all the records from two CTable
objects together -- even if the two tables didn't start out with
exactly the same fields (or even any of the same fields).</P>
<P>It takes all the data records from another CTable object and appends
them into the present table.  Any columns present in the $Other table
but not in the first table, are created (and the corresponding field
values in the first table will all be empty/undef).  Similarly, any
columns present in $t but not present in $Other will be extended
to the correct new length as necessary and the field values in the
original columns will be empty/undef.  Columns present in both will,
of course, have all the data from both the original sets of data.</P>
<P>All data from the second table is brought into the first one.  No
attempt whatsoever is made to eliminate any duplicate records that
might result.</P>
<P>The number of records (length()) after this call is the sum of the
<CODE>length()</CODE> of each of the tables before the operation.</P>
<P>IMPORTANT NOTE: The data from the $Other object is COPIED in memory
into the new object.  This could be hard on memory if $Other is big.
Might want to be sure to discard $Other when you're done with it.</P>
<P>$Other is left untouched by the operation.</P>
<P>All columns from both tables are combined whether or not they are
mentioned in the custom field list of either.</P>
<P>The custom field lists, if present in either table object, are
concatenated into this object's custom field list, but with
duplications eliminated, and order retained.</P>
<P>Any existing custom selections, custom sort order, sort specs, and/or
sort routines are also combined appropriately, with settings from this
object taking precedence over those from $Other anywhere the two have
conflicting settings.</P>
<P><CODE>append_file()</CODE> takes a file name and optional $Params hash.  It uses
those to create a <CODE>new()</CODE> object with data read from the file.  Then,
the new table is appended to $t using <CODE>append()</CODE> and then the new table
is discarded.</P>
<P><CODE>append_files()</CODE> is a convenience function that calls <CODE>append_file()</CODE> on
each file in a list, using the same optional $Params for each.</P>
<P><CODE>append_files_new()</CODE> is the internal routine that implements the
processing done by <CODE>new()</CODE> on the optional list of files to be read.  It
does the following: It calls <CODE>read()</CODE> on the first file in the list.
Then, it calls <CODE>append_files()</CODE> to read the remaining into their own
<CODE>new()</CODE> objects of the same class as $t and using the same $Params to
<CODE>new()</CODE> (if any were supplied).  Then each of these is append()-ed in
turn to $t and discarded.  The final result will be that $t will hold
a concatenation of all the data in all the files mentioned.  However,
consistent with the behavior of append(), the _FileName parameter and
other read()-controlled settings will correspond to the first file
read.  The intermediate objects are discarded.</P>
<P>NOTE: As with <CODE>new()</CODE> and read(), if a non-empty _FieldList Param is
specified, the <CODE>read()</CODE> methods called internally by the append_file*()
methods will read only the fields mentioned and will ignore any other
fields in the files.</P>
<P>
<H2>Combining tables</H2>
<P><CODE>combine()</CODE> adds columns from a second table into the current one.</P>
<P>CAUTION: You should only use <CODE>combine()</CODE> when you have two tables where
all the (possibly selected) records in the second table line up
perfectly with all the (unselected) records in the first table -- in
other words, each table before <CODE>combine()</CODE> should contain a few of the
columns of the new table -- for example, maybe one table contains a
column of file names, and the other contains columns of corresponding
file sizes and modification times.  If you don't understand the
consequences of combine, don't use it or you could end up with some
records whose field values don't refer to the same object.  (Maybe you
meant to use <CODE>append()</CODE> or <CODE>join()</CODE> instead.)</P>
<P>If the second table has a custom field list, only those columns are
brought in.</P>
<P>If any column in the second table has the same name as one in the
current table, the incoming column replaces the one by the same name.</P>
<P>All columns are COPIED from the second table, so the first table owns
the new data exclusively.</P>
<P>If the second table has a selection, only those records are copied, in
selection order.  (select_all() first if that's not what you want.)</P>
<P>The selection in the first table, if any, is ignored during the
combine.  If this isn't what you want, then consider using <CODE>cull()</CODE>
before combine().</P>
<P>Field list and sort order are concatenated (but retaining uniqueness:
second mentions of a field in the combined lists are omitted).</P>
<P>Custom sort routines and sort specs are combined, with those in the
first table taking precedence over any copied in with the same name.</P>
<P>The custom _Selection from the first table, if any, is retained.  (It
will initially omit any records added by extend()).</P>
<P>All other parameters from the first table are retained, and from the
second table are ignored.</P>
<P><CODE>combine()</CODE> calls <CODE>extend()</CODE> after combining to ensure that all columns
have the same length: if either the older or newer columns were
shorter, they will all be set to the length of the longest columns in
the table -- creating some empty field values at the end of the
lengthened columns.</P>
<P><CODE>combine_file()</CODE> does the same as <CODE>combine()</CODE> except starting with a file
name, first creating the $Other object by creating it using
new($Params, $File), then discarding it after combining.</P>
<P>
<H2>Joining tables (Looking up data from another table)</H2>
<P><CODE>join()</CODE> looks up field values from a second table, based on common
values in key fields which may have different or the same names in
each table.  It adds columns to the current table if necessary to hold
any new field values that must be brought in.</P>
<P><CODE>join()</CODE> never adds any new or non-matching records to the table:
records where the lookup fails will simply have empty/undef values in
the corresponding columns.</P>
<PRE>
        ## Example:</PRE>
<PRE>
        $t-&gt;join     ($People,          'FullName', 'FirstAndLast'); ## or
        $t-&gt;join_file(&quot;People.txt&quot;, {}, 'FullName', 'FirstAndLast');</PRE>
<P>Here's how <CODE>join()</CODE> calculates the list of fields to bring in:</P>
<PRE>
        - Legal field names from the optional $Fields list, if supplied
        - Otherwise, the fieldlist() from second table
        - ... minus any fields with same name as $KeyField1 or $KeyField2</PRE>
<P>Join starts by adding new empty columns in the first table for any
field to be brought in from the second but not yet present in the
first.</P>
<P>Here's how <CODE>join()</CODE> calculates the records eligible for lookup:</P>
<PRE>
        - Join only modifies the selected records in the first table
        - Join only looks up values from selected records in second table</PRE>
<P>(If you want all records to be used in both or either table, call the
table's <CODE>select_all()</CODE> method before calling <CODE>join().)</CODE></P>
<P>Then, for every selected record in $t (using the example above), join
examines the FullName field ($KeyField1), and looks up a corresponding
entry (must be 'eq') in the FirstAndLast field ($KeyField2) in the
second table.</P>
<P>IMPORTANT NOTE ABOUT KEY LENGTH: To speed lookup, hash-based indices
are made.  The strings in $Key1 and $Key2 fields should not be so long
that the hash lookups bog down or things could get ugly fast.  There
is no fixed limit to hash key length in Perl, but fewer than 128
characters in length is longer than customary for such things.  (Many
systems require text-based keys to be no longer than 31 characters.)
So be judicious about the values in $Key1 and $Key2 fields.</P>
<P>The first record found in the second table's selection with a matching
value in the key field is then copied over (but only the appropriate
fields are copied, as explained above).  Any field values being
brought over will REPLACE corresponding field values in the first
table, possibly overwriting any previous values if the field being
looked up was already present in the first table and contained data.</P>
<P>The first table's _FieldList is updated to reflect new fields added.</P>
<P>Its _Selection is untouched.</P>
<P>Its _SortOrder is untouched.</P>
<P>Its _SortSpecs are augmented to include any entries from the second
table that should be brought over due to the field additions.</P>
<P>Its _SRoutines are augmented to add new ones from the second table.</P>
<P>All other parameters of table 1 are untouched.</P>
<P>The second table is not modified.  No data structures will be shared
between the tables.  Data is only copied.</P>
<P><CODE>join_file()</CODE> calls <CODE>join()</CODE> after creating a seond table from your $File.</P>
<P><CODE>join_files()</CODE> calls <CODE>join_file()</CODE> repeatedly for each file in a list, but
it is important to note that each file in the list of files to be
joined must have a $Key2 field -- AND, that any values looked up from
the second file will overwrite any values of the same key found in the
first file, and so on.  You probably will not ever need join_files().
It is mainly here for completeness.</P>
<P>
<HR>
<H1>INVERTING A TABLE'S ROWS/COLUMNS</H1>
<PRE>
        ## Re-orient table's data using vals from $ColName as field names...
        $t-invert($ColName)</PRE>
<P>Sometimes a situation gives you a table that's initially organized
with column data in rows, and field names in one of the columns, so
you need to flip the table in order to be able to work meaningfully
with it.</P>
<P>&#147;Inverting&#148; a table means to rewrite each row as a column. One row is
designated to be used as the field names.</P>
<P>For example, consider this table:</P>
<PRE>
        F01    F02   F03   F04
        ------------------------
        First  Chris Agnes James
        Last   Bart  Marco Nixon
        Age    22    33    44</PRE>
<P>Calling <CODE>invert()</CODE> using field names from &#147;F01&#148;...</P>
<PRE>
        $t-&gt;invert('F01');</PRE>
<P>... would change the table to look like this:
</P>
<PRE>

        First  Last  Age
        ----------------
        Chris  Bart  22
        Agnes  Marco 33
        James  Nixon 44</PRE>
<P>The field F01 which formerly contained the field names, is now gone,
and the remaining data columns have been converted from their old row
orientation into a column orientation.</P>
<P>
<HR>
<H1>PROGRESS MESSAGES</H1>
<PRE>
        ## Printing a progress message....
</PRE>
<PRE>

        $t-&gt;progress($Msg)       ## Print a message per current settings</PRE>
<PRE>
        ## Progress settings applying to this object only...</PRE>
<PRE>
        $t-&gt;progress_get()       ## Get current progress setting</PRE>
<PRE>
        $t-&gt;progress_set(1)      ## Use progress_default() method
        $t-&gt;progress_set($Sub)   ## Set a custom progress routine
        $t-&gt;progress_set(0)      ## Disable progress
        $t-&gt;progress_set(undef)  ## Use class's settings (default)...</PRE>
<PRE>
        ## Class's settings (for instances with _Progress == undef)</PRE>
<PRE>
        $t-&gt;progress_class()     ## Get current setting.</PRE>
<PRE>
        $t-&gt;progress_class(1)    ## Use progress_default() method
        $t-&gt;progress_class($Sub) ## Set shared custom prog routine
        $t-&gt;progress_class(0)    ## Disable class-default progress
</PRE>
<PRE>

        Data::CTable-&gt;progress_class(..) ## Call without an object</PRE>
<PRE>
        ## Call builtin default progress method regardless of settings</PRE>
<PRE>
        $t-&gt;progress_default($Msg) ## Default prog. routine for class</PRE>
<PRE>
        ## Generate a warning (used internally by other methods)</PRE>
<PRE>
        $t-&gt;warn($Msg)   ## In this class, calls progress_default()</PRE>
<PRE>
        ## Timed progress: print msg to start, then at most once/2 sec</PRE>
<PRE>
        $t-&gt;progress_timed($Op, $Item)  ## Re-print msg every 2 sec
        $t-&gt;progress_timed($Op, $Item, $Pos, $Tot) ##... with % readout
        $t-&gt;progress_timed($Op, $Item, $Pos, $Tot, $Wait) ## Not 1st x</PRE>
<PRE>
        $t-&gt;progress_timed_default($Msg)  ## Called by progress_timed</PRE>
<P>Data::CTable is especially useful in creating batch-oriented
applications for processing data.  As such, routines that may perform
time-consuming tasks will, by default, generate helpful progress
messages.  The progress mechanism is highly customizable, however, to
suit the needs of applications that don't require this output, or that
require the output to go somewhere other than STDERR or the console.</P>
<P>The default progress routine is one that prints a message with a
date/time stamp to STDERR if and only if STDERR is an interactive
terminal, and otherwise is silent.</P>
<P>You could write a custom progress routine that does something else or
something in addition (e.g. logs to a file or syslog).  The custom
routine could either be implemented by overriding the
<CODE>progress_default()</CODE> method in a subclass, or by calling <CODE>progress_set()</CODE>
in any instance.</P>
<P>The custom progress routine, if any, is stored in the _Progress
parameter of the object.  But use <CODE>progress_set()</CODE> and <CODE>progress_get()</CODE> to
access it.</P>
<P>The interface for your custom progress routine should be:</P>
<PRE>
        sub MyProgress {my ($Obj, $Message) = @_; chomp $Message; .....}</PRE>
<P>In other words, the routine takes a single message which may or may
not have a trailing newline.  It should always chomp the newline if
present, and then do its business... which generally will include
printing or logging a message (usually with a newline added).</P>
<P>The default, built-in progress routine for Data::CTable is:</P>
<PRE>
        sub progress_default
        {
            my ($this, $msg) = @_; 
            chomp $msg; 
</PRE>
<PRE>

            print STDERR (localtime() . &quot; $msg\n&quot;) if -t STDERR;</PRE>
<PRE>
            return(1);   ## Indicate progress actually completed
        }</PRE>
<P>Of course, you are free to call this method directly at any time, and
it will do its thing regardless of other progress-enabling settings.
But the preferred way is to first set the settings and then call
progress().</P>
<P>The <CODE>warn()</CODE> method always calls <CODE>progress_default()</CODE> -- i.e. warnings
will display even if progress is otherwise disabled or overridden at
the object or class level.  However, you could create a subclass that
changes warn()'s behavior if desired.  (For example, it could just
call perl's builtin warn function, or be even more forceful,
generating warnings even if STDERR is not a terminal, for example.)</P>
<P>The <CODE>progress_set()</CODE> method may be used to override the progress routine
for an individual object (set to 1/true for default behavior, or
0/undef/false to disable progress for that object entirely).</P>
<P>Call <CODE>progress_class()</CODE> to set similar values to control the global
default behavior (e.g. turning on/off default progress behavior for
all instances), but be cautious about using this approach in any
environment where other programs might be accessing the same loaded
class data, since the setting is stored in a class-owned global
($Data::CTable::DefaultProgress).</P>
<P>Manipulating the class-default settings is only recommended in batch
or shell-script environments, not in mod_perl Web applications where
the module stays loaded into the Perl environment across multiple
invocations, for example.</P>
<P>If you want a particular method (e.g. <CODE>read()</CODE> but not <CODE>write())</CODE> to be
silent, you could make a subclass and could override that method with
an implementation that first disables progress, calls the SUPER::
method, and then restores the progress setting to its original
setting.</P>
<P>
<H2>Timed progress</H2>
<P>Timed progress is a way of printing periodically-recurring progress
messages about potentially time-consuming processes to the terminal.</P>
<P>For example, consider the following messages which might appear every
2 seconds during a lengthy <CODE>read()</CODE> operation:</P>
<PRE>
        Reading... 0 (0%)
        Reading... 2000 (4%)
        ...
        Reading... 38000 (96%)
        Reading... 40000 (100%)</PRE>
<P>The <CODE>progress_timed()</CODE> method is called internally by potentially
time-consuming processes (read(), write(), and sort()), and you may
want to call it yourself from your own scripts, to produce
weary-programmer-soothing visual output during otherwise
panic-producing long delays.</P>
<P>Generally, <CODE>progress_timed()</CODE> is called with the $Wait parameter set to
true, which delays the display of any messages until 2 seconds have
passed, so no messages will be displayed unless the process actually
does end up being slower than 2 seconds.</P>
<P>Parameters are:</P>
<PRE>
        $Op    The string that identifies the &quot;operation&quot; taking place
        $Item  A milestone such as a number or datum to indicate progress
        $Pos   A numeric position against the (maybe estimated) baseline
        $Tot   The baseline.  If estimated, don't re-estimate too often
        $Wait  If true, skip printing the first message for this $Op</PRE>
<P>All parameters except $Op are optional.</P>
<P><CODE>progress_timed()</CODE> has a throttle that keeps it from re-triggering more
often than every 2 seconds for any given sequence of the same $Op.
The clock is restarted each time you call it with a different $Op or
$Tot from the previous call (on the assumption that if the operation
or the baseline changes then that fact should be noted).</P>
<P>The messages printed will start with &#147;$Op... &#148;.</P>
<P>If you supply $Item, which could be a number or a string, the messages
will then show the $Item after the $Op.</P>
<P>If you supply BOTH $Pos and $Tot, then a percentage will be calculated
and added to the readout; otherwise omitted.</P>
<P>If you supply $Wait, the first message (only) that uses this $Op will
be skipped, and the next one won't appear for at least 2 seconds.</P>
<P>If using $Pos and $Tot to display percentages for your user, be sure
to call <CODE>progress_timed()</CODE> one final time when $Pos == $Tot so your user
sees the satisfying 100% milestone.  This &#147;completion&#148; call will not
be skipped even if 2 seconds have not passed since the previous timed
progress message was printed.</P>
<P>Althought <CODE>progress_timed()</CODE> is designed to cut down on too much visual
output when called often in a tight loop, remember that it still takes
some processing time to call it and so if you call it too frequently,
you're slowing down the very loop you wish were running faster.</P>
<P>So, you might want to call it every tenth or 100th or even 1000th time
through a tight loop, instead of every time through, using the mod (%)
operator:</P>
<PRE>
        $t-&gt;progress_timed(....) if ($LoopCount % 100) == 0;</PRE>
<P><CODE>progress_timed_default()</CODE> is the method called internally by
<CODE>progress_timed()</CODE> to actually print the messages it has prepared.  In
this implementation, <CODE>progress_timed_default()</CODE> just calls
progress_default().  That is, it ignores all other progress-inhibiting
or -enhancing settings so delay-soothing messages will print on the
terminal even if other messages are turned off.</P>
<P>This is because the author assumes that even if you don't want all
those other progress messages, you might still want these ones that
explain long delays.  If you REALLY don't, then just make yourself a
lightweight subclass where <CODE>progress_timed_default()</CODE> is a no-op, or
maybe calls regular progress().  For example:</P>
<PRE>
        BEGIN {package Data::CTable::Silent; use vars qw(@ISA); 
               @ISA=qw(Data::CTable); sub progress_timed_default{}}</PRE>
<PRE>
        ## Later...
        my $t = Data::CTable::Silent-&gt;new(...);</PRE>
<P>
<HR>
<H1>Rejecting or reporting on groups of records and continuing</H1>
<P>Use utility methods <CODE>omit_warn()</CODE> and <CODE>omit_note()</CODE> to conditionally omit
some records from a table and warn (or &#147;note&#148;) if any were affected.</P>
<P>Use <CODE>select_extract()</CODE> to do the same thing but without actually
removing the extracted records from the table, and restoring the
original selection before select_extract was called.</P>
<P>If you supply a file name as the 4th argument, the omitted records
will be extracted to a file for later reference.</P>
<P>If you supply a message prefix as the 5th argument, a string other
than &#147;WARNING&#148; or &#147;Note&#148; may be specified.</P>
<PRE>
        # Reject with a progress message prefixed by &quot;WARNING:&quot;</PRE>
<PRE>
        $t-&gt;omit_warn(FirstName =&gt; sub{!length($_)}, &quot;First name is empty&quot;);</PRE>
<PRE>
                Mon Aug 23 08:24:15 2004 WARNING: Omitting 2 of 78243 records (now 78241): First name is empty.</PRE>
<PRE>
        # Reject with a progress message prefixed by &quot;Note:&quot;, with output to a file</PRE>
<PRE>
        $t-&gt;omit_note(FirstName =&gt; sub{!length($_)}, &quot;First name is empty&quot;, &quot;empty.names.txt&quot;);</PRE>
<PRE>
                Mon Aug 23 08:24:15 2004 Note: Omitting 2 of 78243 records (now 78241): First name is empty.
                Mon Aug 23 08:24:15 2004 Writing bad.firstname.txt...
                Mon Aug 23 08:24:15 2004 Wrote   bad.firstname.txt.</PRE>
<PRE>
        # Extract some items, leaving original selection intact</PRE>
<PRE>
        $t-&gt;select_extract(FirstName =&gt; sub{!length($_)}, &quot;First name is empty&quot;, &quot;empty.names.txt&quot;);</PRE>
<PRE>
                Mon Aug 23 08:24:15 2004 Note: Extracting 2 of 78243 records: First name is empty.</PRE>
<P>
<HR>
<H1>DEBUGGING / DUMPING</H1>
<PRE>
        ## Print some debugging output...</PRE>
<PRE>
        $t-&gt;out()             ## Pretty-print $t using Data::ShowTable</PRE>
<PRE>
        $t-&gt;dump()            ## Dump $t using Data::Dumper
        $t-&gt;dump($x, $y)      ## Dump anything else using Data::Dumper</PRE>
<PRE>
        ## Print some debugging output and then die.</PRE>
<PRE>
        die $t-&gt;out()         ## Same but die afterwards.</PRE>
<PRE>
        die $t-&gt;dump()        ## Same but die afterwards.
        die $t-&gt;dump($x, $y)  ## Same but die afterwards.</PRE>
<P>These two methods can be very helpful in debugging your scripts.</P>
<P>The <CODE>out()</CODE> method, which has many options, is described in complete
detail in the section below titled &#147;FORMATTED TABLES&#148;.  In short, it
prints a nicely-formatted diagram of $t, obeying the custom field list
if any and custom selection if any.</P>
<P>The <CODE>dump()</CODE> method uses the Data::Dumper module to call &amp;Dumper() on
the table itself (by default) and prints the result to STDERR.  If you
specify any number of other values, those will be dumped instead using
a single call to &amp;Dumper (rather than individually).</P>
<P>
<H2>Optional module dependencies</H2>
<P>These methods require the otherwise-optional modules shown here:</P>
<PRE>
        out()       Data::ShowTable  
        dump()      Data::Dumper</PRE>
<P>You'll get a warning at runtime if you try to call either method
without the appropriate module installed on your system.</P>
<P>
<HR>
<H1>MISCELLANEOUS UTILITY METHODS</H1>
<P>The following utilities are methods of the Data::CTable object.  They
may be called directly by clients, subclassed, or used by subclass
implementations as needed.</P>
<PRE>
        ## Get cache file path (all args optional: defaulted from $t)</PRE>
<PRE>
        $f  = $t-&gt;prep_cache_file($FileName, $CacheExtension, $CacheSubDir)</PRE>
<PRE>
        ## Verify all directories in a path, creating any needed ones.</PRE>
<PRE>
        $ok = $t-&gt;verify_or_create_path($DirPath, $Sep)</PRE>
<PRE>
        ## Testing readability / writeability of a proposed file</PRE>
<PRE>
        $ok = $t-&gt;try_file_read ($Path); ## Opens for read; then closes
        $ok = $t-&gt;try_file_write($Path); ## Opens for write; then deletes</PRE>
<PRE>
        ## Getting parameters from object with optional overrides</PRE>
<PRE>
        $param = $t-&gt;getparam($Params, $Param)</PRE>
<P><CODE>prep_cache_file()</CODE> is the internal method used by both <CODE>read()</CODE> and
<CODE>write()</CODE> to calculate the name of a cache file to be used for a given
$FileName.</P>
<P>It calculates the path to the cache file that corresponds to the given
$FileName (which may be a bare file name, a relative path, or a
partial path, as long as it obeys the current platform's path format
rules).  All arguments are optional and if absent (undef), will be
defaulted from the corresponding parameters in $t.</P>
<P>In addition to calculating the path and file name, it also prepends
the &#147;current directory&#148; path if there was no path.  Then it checks
that all directories mentioned in the path actually exist.  If not, it
fails.  Then, it checks that EITHER the file exists and is readable,
OR it does not exist but would be writeable in that directory.  If any
of these directory creations or file checks fails, then undef is
returned (and there would be no cache file).</P>
<P>You may call it with no arguments on a file that has been <CODE>read()</CODE> to
find the path to the cache file that may have been used and/or
created, if any.</P>
<P>You may call it with a file name that was written to, to see what the
corresponding written cache file would be.</P>
<P>For example:</P>
<PRE>
        ## Get name of cache file used or created by read and delete it.</PRE>
<PRE>
        $RCache = $t-&gt;prep_cache_file() and unlink($RCache);</PRE>
<PRE>
        ## Cache on write() and get name of file and delete it.</PRE>
<PRE>
        $Written = $t-&gt;write(_CacheOnWrite=&gt;1, _FileName=&gt;&quot;Foo.txt&quot;);
        $WCache  = $t-&gt;prep_cache_file($Written) and unlink($WCache);</PRE>
<P><CODE>verify_or_create_path()</CODE> is the internal routine used by read(),
write(), and the cache-writing logic, that makes sure a requested file
path exists (by creating it if necessary and possible) before any file
is written by this module.</P>
<P>(If you don't like this module's tendency to try to create
directories, make yourself a subclass in which this routine simply
checks -d on its $Path argument and returns the result.)</P>
<P>It must be called with a full or partial path TO A DIRECTORY, NOT A
FILE.  You may supply $Sep, a platform-appropriate separator character
(which defaults correctly for the runtime platform if you don't).</P>
<P>Returns true if the path verification and/or creation ultimately
succeeded, false otherwise (meaning that, after this call, there is no
such directory on the system and so you should not try to write a file
there).</P>
<P><CODE>try_file_read()</CODE> and <CODE>try_file_write()</CODE> are the internal methods called
by <CODE>prep_cache_file()</CODE> as well as by <CODE>read()</CODE> and <CODE>write()</CODE> to preflight
proposed file reading and writing locations.</P>
<P><CODE>try_file_read()</CODE> opens a file for read and closes it again; returns
true if the open was possible.</P>
<P><CODE>try_file_write()</CODE> opens a file for write and closes it again, deleting
it if successful.  Returns true if the open for write and the delete
were successful.  (Be aware that this call will actually delete any
existing file by this name.)</P>
<P>The reason that failure to delete causes <CODE>try_file_write()</CODE> to fail is
that successful cacheing depends on the ability to delete cache files
as well as create them or write to them.  A file in a location that
couldn't be deleted will not be used for cacheing.</P>
<P><CODE>getparam()</CODE> looks up a named parameter in a params hash if it exists
there, otherwise looks it up in the object, thereby allowing $Params
to shadow any parameters in $this.</P>
<P>This internal routine is used by any methods that allow overriding of
parameters in the object when using a named-parameter calling
interface.  It should be used by any subclasses that also wish to use
a named-parameter calling convention.  For example:</P>
<PRE>
        my $this        = shift;
        my $Params      = (@_ == 1 ? {_FieldList =&gt; $_[0]} : {@_});</PRE>
<PRE>
        my($FieldList, $Selection) = map {$this-&gt;getparam($Params, $_)} 
        qw(_FieldList  _Selection);</PRE>
<P>
<HR>
<H1>GENERAL-PURPOSE UTILITY FUNCTIONS</H1>
<P>These general-purpose utility routines are defined in the Data::CTable
module but are not method calls.  You may optionally import them or
call them by their fully-qualified name.</P>
<PRE>
        use Data::CTable qw(
                            guess_endings
                            guess_delimiter
                            path_info
                            path_is_absolute
                            min
                            max
                            );</PRE>
<PRE>
        ## File-format guessing</PRE>
<PRE>
        my $E = &amp;guess_endings($IOHandle) ## Guess txt file line endings
        my $D = &amp;guess_delimiter($String) ## Tab if found, else comma</PRE>
<PRE>
        ## Cross-platform file path analysis</PRE>
<PRE>
        my $Info = path_info();   ## Hash: 3 of platform's path values:
        my ($Sep,                 ## ... path separator (  / on Unix)
            $Up,                  ## ... &quot;up&quot; component (../ on Unix)
            $Cur) =               ## ... curr. dir path ( ./ on Unix)
        @$Info{qw(sep up cur)};</PRE>
<PRE>
        my $Abs = path_is_absolute($Path)  ## Check path type</PRE>
<PRE>
        ## Our old favorites min and max</PRE>
<PRE>
        $x = max($x, 0);          ## Should have been part of Perl...
        $x = min($x, 100);</PRE>
<P><CODE>guess_endings()</CODE> tries to figure out whether an open IO::File handle
has DOS, Mac, or Unix file endings.  It reads successively large
blocks of the file until it either finds evidence of at least two
separate line endings (of any type, but presumably they are the same),
or until it reaches the end of the file.  Then, it takes the resulting
block and searches for the first qualifying line ending sequence it
finds, if any.  This sequence is then returned to the caller.  If it
returns undef, it was not able to find any evidence of line endings in
the file.</P>
<P><CODE>guess_delimiter()</CODE> takes a string buffer and returns a &#147;,&#148; unless it
finds a tab character before the first comma in the $String, if any,
in which case a tab is returned.</P>
<P><CODE>path_info()</CODE> returns a hash of three helpful strings for building and
parsing paths on the current platform.  Knows about Mac, Dos/Win, and
otherwise defaults to Unix.</P>
<P><CODE>path_is_absolute($Path)</CODE> returns true if it thinks the given path
string is an absolute path on the current platform.</P>
<P>
<HR>
<H1>IMPLEMENTATION LIMITATIONS</H1>
<DL>
<DT><STRONG>Column (field) names must not start with underscore</STRONG><BR>
<DD>
This object is implemented as a blessed hash reference.  By
convention, keys that do not start with underscore are data columns
and the key is the field name.  Keys that do start with underscore
refer to parameters or other data structures stored in the object.
<P>Consequently, no field names may start with underscore.  When a file
is read from disk, any field names that DO start with underscores will
have the leading underscores stripped off.  Strange things could then
occur if the field names are then no longer unique.  For example,
field &#147;A&#148; and &#147;_A&#148; in the data file would be treated as the single
field &#147;A&#148; after the file was read.</P>
<P></P>
<DT><STRONG>Field values are always read as strings</STRONG><BR>
<DD>
Field values when written to a file are necessarily converted to
strings.  When read back in, they are read as strings, regardless of
original format.  The sole exception is the empty string which is read
back in as undef for efficiency.
<P>An exception is when the _CacheOnWrite feature is used: field values
stored internally as integers or other scalar types may be saved and
later restored as such.  However, you should not rely on this
behavior.</P>
<P></P>
<DT><STRONG>Undef vs. empty</STRONG><BR>
<DD>
Empty field values are stored as &#147;undef&#148; for efficiency.  This means
that programs should generally not rely on any differences between ``''
and undef in field values.  However, when working with large but
sparse tables, programs should take care not to convert undef values
to empty strings unnecessarily since the separate string objects
consume considerably more memory than undef.
<P></P></DL>
<P>
<HR>
<H1>CONTRIBUTIONS</H1>
<P>Corrections, bug reports, bug fixes, or feature additions are
encouraged.  Please send additions or patches with a clear explanation
of their purpose.  Consider making additions in the form of a subclass
if possible.</P>
<P>I'm committed to bundling useful subclasses contributed by myself or
others with this main distribution.</P>
<P>So, if you've got a subclass of Data::CTable (which should have a name
like Data::CTable::YourClassName) and you would like it included in
the main distribution, please send it along with a test script and
I'll review the code and add it (at my discretion).</P>
<P>If you've got a module that uses, augments, or complements this one,
let me know that, too, and I'll make appropriate mention of it.</P>
<P>
<HR>
<H1>SEE ALSO</H1>
<P>The Data::CTable home page:</P>
<PRE>
        <A HREF="http://christhorman.com/projects/perl/Data-CTable/">http://christhorman.com/projects/perl/Data-CTable/</A></PRE>
<P>The implementation in CTable.pm.</P>
<P>The test.pl script, other subclasses, and examples.</P>
<P>The Data::ShowTable module.</P>
<P>The Data::Table module by Yingyao Zhou &amp; Guangzhou Zou.</P>
<P>The perlref manual page.</P>
<P>
<HR>
<H1>AUTHOR</H1>
<P>Chris Thorman &lt;<A HREF="mailto:chthorman@cpan.org">chthorman@cpan.org</A>&gt;</P>
<P>Copyright (c) 1995-2002 Chris Thorman.  All rights reserved.</P>
<P>This program is free software; you can redistribute it and/or modify
it under the same terms as Perl itself.</P>

</BODY>

</HTML>
